#import "@preview/scripst:1.1.1": *

= 物理内存管理

== 地址空间

#note(subname: [问题])[
  - *为什么要建立存储层次结构？*
    - 根本原因：速度差距（CPU vs. 存储器）

      计算机中不同存储介质的速度和容量差距极大：
      #three-line-table[
        | 存储层次            | 示例         | 访问延迟         | 容量      | 成本（每bit） |
        | --------------- | ---------- | ------------ | ------- | -------- |
        | 寄存器             | CPU 内部     | $~$1ns         | 几十字节    | 💰极高     |
        | Cache（L1/L2/L3） | SRAM       | 几 ns $~$ 数十 ns | KB $~$ MB | 高        |
        | 主存（RAM）         | DRAM       | 百 ns         | GB      | 中        |
        | 磁盘 / SSD        | HDD / NAND | 微秒 $~$ 毫秒      | TB      | 低        |
        | 外存（网络/云）        | 远程存储       | 毫秒 $~$ 秒       | 无限      | 💸最低     |
      ]
      CPU 一次指令可能只需 1ns，但访问内存可能需要 100ns 甚至更久；如果没有层次结构，CPU 大部分时间都在“等内存”
    - 解决思路：分层存储 + 局部性原理
      - 时间局部性（Temporal Locality）：刚访问过的数据很快还会用到
      - 空间局部性（Spatial Locality）：访问某个地址后，很可能访问其邻近地址
      于是系统通过“存储层次结构（Storage Hierarchy）”解决性能与容量的矛盾：
      ```
      寄存器
        ↓
      Cache (L1/L2/L3)
        ↓
      主存（RAM）
        ↓
      磁盘 / SSD
        ↓
      网络 / 云存储
      ```
  - *如何描述访问的存储单元？*
    - 计算机中访问任何数据，必须通过“地址（Address）”来标识存储单元
    - 存储单元的基本单位：字节（Byte）
      - 每个存储单元（最小可寻址单位）通常为 1 Byte（8 位）
      - 内存被线性编号：0, 1, 2, 3, ...
      - 每个单元都有唯一的物理地址
    - 存储单元的逻辑分组
      - 字（Word）：CPU 一次读写的自然单位（如 32 位 CPU 的 word = 4 字节）
      - 块 / 页（Block / Page）：
        - Cache 层：按块（Cache line）管理，如 64B
        - 虚拟内存层：按页（Page）管理，如 4KB
      - 所以，“存储单元”可以是字节、字、块、页等不同粒度的逻辑访问单位
  - *编译器、CPU和系统总线使用的存储单元地址有什么异同？*
    #three-line-table[
      | 层级   | 地址类型            | 由谁使用          | 典型表示          | 是否唯一      | 说明           |
      | ---- | --------------- | ------------- | ------------- | --------- | ------------ |
      | 编译器  | *符号地址 / 逻辑地址* | 编译器           | `a`, `main+4` | 否（作用域内有效） | 程序源码视角       |
      | CPU  | *虚拟地址*        | CPU + MMU     | `0x7fff_1234` | 每进程唯一     | 用户程序执行时看到的地址 |
      | 系统总线 | *物理地址*        | 总线 / DRAM 控制器 | `0x0034_1234` | 系统全局唯一    | 对应真实内存芯片单元   |
    ]
    - 编译器视角：符号地址（Symbolic Address）
      - 程序源码中使用变量名、函数名访问数据
      - 对编译器来说，`a`是一个符号地址
      - 编译器通过符号表将变量映射为逻辑地址（logical address）或相对地址：`main() 开始地址 + 偏移量`
      - 编译器不知道实际物理内存位置，地址相对于程序本身，是逻辑（虚拟）的
    - CPU视角：虚拟地址（Virtual Address）
      - 当程序运行时，CPU 实际访问的不是“物理地址”，而是“虚拟地址”
      - 虚拟地址 → 经过 MMU（内存管理单元） → 转换为 物理地址：`虚拟地址 0x7fff_1234 → MMU → 物理地址 0x0034_1234`
      - 每个进程拥有独立的虚拟地址空间，隔离不同进程（安全性），简化编译器和程序员的地址管理
    - 系统总线视角：物理地址（Physical Address）
      - 内存总线传递的地址是物理地址，对应真实内存芯片的存储单元
      - 物理地址由 MMU 翻译结果 产生
      - 内核负责维护虚拟地址与物理页帧的映射（页表）
]

=== 计算机的存储层次

==== 物理地址、逻辑地址、虚拟地址

*物理地址、逻辑地址、虚拟地址*
- *物理地址*(PA, Physical Address) ：用于内存芯片级的单元寻址，与处理器和CPU连接的*地址总线*相对应
- *逻辑地址*(LA, Logical Address) ：在程序的*编译和链接阶段生成*，表示程序中的地址偏移，它在载入内存之前使用
- *虚拟地址*(VA，Virtual Address)：操作系统在程序加载过程中，将逻辑地址调整或映射到适当的虚拟地址空间

*虚拟地址转换为物理地址*
- 段式管理:
  - 虚拟地址通过*分段*转换为物理地址
  - 虚拟地址也称为*线性地址*(LA，Linear Address)
    - 虚拟地址被分成段（code/data/stack）
    - 通过段基址+偏移量映射到物理地址
    - 常见于早期 x86 实模式
- 页式管理:
  - 虚拟地址通过*分页*转换为物理地址
    - 把虚拟地址空间划分为固定大小的“页”（Page）
    - 由页表（Page Table）记录“虚拟页 → 物理页帧”的映射
    - 现代操作系统主要采用此方式
- 段页式管理:
  - 虚拟地址先通过*分段*，再通过*分页*转换为物理地址
  - 先用段选择，再在段内分页映射，多见于 x86 保护模式（32位时代）

==== 计算机的存储层次结构

*计算机的存储层次结构*

#figure(
  image("pic/2025-10-16-15-50-12.png", width: 70%),
  numbering: none,
)
CPU、内存、I/O设备之间通过*总线（Bus）*通信的基本体系结构
- CPU内部：
  - 算术逻辑单元（ALU）；控制逻辑；寄存器（Register）；高速缓存（Cache）；存储管理单元（MMU）
  - 快表（TLB）：用于加速虚拟地址到物理地址的转换
- 外部设备：
  - 内存（Memory）：主存储器，容量较大
  - I/O设备：磁盘、网卡等外围
  - 三者之间通过*系统总线（Bus）*通信

*计算机的存储多层结构*

#figure(
  image("pic/2025-10-16-15-54-50.png", width: 60%),
  numbering: none,
)
比较新的各种存储介质的访问速度参数：
- 金字塔层次结构：越靠近CPU速度越快，容量越小，价格越贵
  #three-line-table[
    | 层次             | 典型组件  | 访问速度   | 单位容量成本 | 容量大小  |
    | -------------- | ----- | ------ | ------ | ----- |
    | 寄存器            | CPU内部 | $<1$ns   | 极高     | 字节级   |
    | L1/L2/L3 Cache | SRAM  | 1–10ns | 高      | KB–MB |
    | 主存（DRAM）       | DRAM  | 100ns  | 中      | GB    |
    | 外存（SSD/HDD）    | 磁盘    | μs–ms  | 低      | TB    |
    | 远程/云存储         | 网络    | ms–s   | 极低     | 无上限   |
  ]
  当Cache未命中、缺页时，访问层次会从上往下逐级降低速度

==== 地址空间与内存管理

*操作系统的抽象：地址空间*
#figure(
  image("pic/2025-10-16-15-59-48.png", width: 80%),
  numbering: none,
)
- *MMU（内存管理单元）*在多进程系统中的作用
  - 每个进程（P1, P2, P3, P4）都有独立的逻辑/虚拟地址空间
  - 这些虚拟空间通过 MMU 转换到同一物理内存
  - 操作系统核心在底层维护虚拟页与物理页的对应关系（页表）

*内存管理*
- 操作系统中的*内存管理方式*
  - 重定位(relocation)
  - 分段(segmentation)
  - 分页(paging)
  - 虚拟存储(virtual memory/storage)
- *操作系统的内存管理高度依赖硬件*
  - 与计算机存储架构紧耦合
  - MMU (内存管理单元): 处理CPU存储访问请求的硬件

=== 地址和地址空间

*地址空间的定义*
- 三种地址空间的视角不同
  - 物理地址空间：系统总线视角的地址空间
    - 起始地址0，直到$max_"phy"$
  - 虚拟地址空间：CPU视角的地址空间
    - 起始地址0，直到$max_"virt"$
  - 逻辑地址空间：编译器视角的地址空间
    - 起始地址0，直到$max_"prog"$

*逻辑地址生成*

#figure(
  image("pic/2025-10-16-22-14-05.png", width: 80%),
  numbering: none,
)
- 编译阶段（Compile Time）
  - 编译器假设程序从地址 0 开始
  - 生成逻辑地址（相对地址 / 偏移地址）
  - 如果目标地址确定 → 生成绝对地址（absolute address）
  - 否则生成可重定位代码（relocatable code）
    ```
    foo();
    ```
  编译后汇编代码中跳转 `jmp _foo`，但 `_foo` 的真实地址此时未知
- 汇编与链接阶段（Assemble & Link）
  - 汇编器将符号名转换为逻辑地址（如 `_foo → 75`）
  - 链接器将多个模块的地址重排、合并成一个统一的逻辑地址空间
  - 结果：形成从 0 起的程序逻辑地址空间
    ```
    汇编时：jmp 75
    链接后：jmp 175
    ```
- 装载阶段（Load Time）
  - 当程序被加载到内存中时，操作系统可能会将其放在任意起始地址
  - 加载器根据起始位置（如 1000）将所有逻辑地址“重定位”成虚拟地址
    ```
    jmp 175 → jmp 1175
    ```
  - 这是加载时地址绑定（Load-time Binding）
- 执行阶段（Execution Time）
  - 程序运行后，CPU 执行指令中的地址是虚拟地址（VA）
  - MMU（内存管理单元）负责运行时地址绑定（Run-time Binding）
  - 即把虚拟地址转换为物理地址（VA → PA）

*地址生成时机*
- 编译时
  - 假设起始地址*已知*
  - 如果起始地址改变，必须重新编译
- 加载时
  - 如编译时起始地址*未知*，编译器需生成可重定位的代码 (relocatable code)
  - 加载时，位置可不固定，生成绝对（虚拟）地址
- 执行时
  - 执行时代码不可修改
  - 需*地址转换(映射)硬件*支持

*地址生成过程*
- CPU
  - MMU：进行虚拟地址和物理地址的*转换*
  - CPU控制逻辑：给总线发送*物理地址*请求
- 内存
  - 发送*物理地址*的内容给CPU
  - 接收CPU数据到物理地址
- 操作系统
  - 建立虚拟地址VA和物理地址PA的映射

*地址检查*

#figure(
  image("pic/2025-10-16-22-13-42.png", width: 80%),
  numbering: none,
)
- 执行流程
  #three-line-table[
    | 步骤    | 行为                  | 说明                 |
    | ----- | ------------------- | ------------------ |
    | (1)   | CPU 发出虚拟地址 (Vaddr)  | 指令或数据访问            |
    | (2.1) | MMU 查 TLB（页表缓存）     | 若命中 → 得到物理地址 Paddr |
    | (2.2) | 若 TLB 未命中 → 从内存页表查找 |          \          |
    | (3)   | 页表返回物理页帧号           | 结合页内偏移形成 Paddr     |
    | (4)   | 检查访问权限、界限是否合法       | 若越界/无权限 → 触发异常     |
    | (5)   | 从物理内存中读写数据          | 或触发缺页异常加载到内存       |
  ]
- 异常与处理
  - 若地址不合法或越界：
    - MMU 触发“地址异常（Address Fault）”
    - CPU 跳转至异常处理例程（由操作系统负责）
    - 可能导致：
      - 缺页中断（Page Fault）
      - 访问违规（Segmentation Fault）

=== 虚拟存储的作用

*外存的缓存*：虚拟内存可作为外存的缓存
- 常用数据放在物理内存中
- 不常用数据放在外存
- 运行的程序直接用虚存地址，不用关注具体放在物理内存还是外存

*简化应用编译和加载运行*：每个运行程序具有独立的地址空间，而不管代码和数据在物理内存的实际存放，从而简化：
- 编译的执行程序*链接*
- 操作系统的执行程序*加载*
- *共享*：动态链接库、共享内存
- 内存分配：物理不连续，*虚拟连续*

*保护数据*：虚拟内存可保护数据
- *独立的地址空间*使得区分不同进程各自内存变得容易
- 地址转换机制可以进行可读/可写/可执行的检查
- 地址转换机制可以进行特权级检查

#note(subname: [小结])[
  - 存储层次结构的作用
    - 存储效率（速度、容量、成本）、简化访问过程、存储保护
  - 存储单元的地址和地址空间
    - 逻辑地址、虚拟地址、物理地址
  - 操作系统通过提供虚拟存储来实现存储层次结构的作用
]

== 内存分配

#note(subname: [问题])[
  操作系统如何管理物理内存的使用状态？

  - 操作系统管理物理内存的目标
    - 操作系统必须维护物理内存资源的使用状态，以便能：
    - *记录* 哪些内存块被使用、哪些空闲
    - *分配* 新的内存区域
    - *回收* 进程结束时释放的内存
    - *防止冲突*（不同进程不能重叠使用同一物理页）
    - *提高效率*（避免过多碎片、支持快速查找）
  - 操作系统的核心数据结构：内存分配表（Memory Allocation Table）
    - 操作系统用数据结构（表/位图/链表）来表示物理内存的使用状态
  - 物理内存分配的基本思想：连续内存分配（Contiguous Allocation）
    - 固定分区（Fixed Partitioning）
      - 内存被预先划分为若干固定大小的分区；每个分区可容纳一个进程；分区表记录每个区的状态（空闲/已用）
    - 动态分区（Dynamic Partitioning）
      - 不预先划分；每次根据进程需要，动态分配一块连续区域；释放后重新合并空闲区
  - 非连续内存管理（分页/分段）
]

=== 内存分配

==== 内存分配方式

*内存分配方式*：运行应用所占内存按存储数据特征划分成多个段(Segment)
- 静态内存分配
- 动态内存分配
  - 连续内存分配
  - 非连续内存分配
- 内存管理的目的
  - 让应用方便/灵活/高效地使用有限内存

*动态内存分配接口*

#figure(
  image("pic/2025-10-18-12-45-07.png", width: 80%),
  numbering: none,
)

*静态内存分配*：静态内存分配是指编译时的内存分配
- 包括全局、静态变量和代码
- 位于全局/静态数据段、常量数据段、代码段

==== 动态内存分配

*动态内存分配*：动态内存分配是指运行时的内存分配
- 栈(stack)
  - 局部变量
- 堆(heap)
  - `malloc()`函数分配内存
  - `free()`函数释放内存
- 使用动态内存分配的原因
  - 无法事先确定程序运行所需要的内存大小
  - 经常直到程序实际运行时，才知道某些数据结构的大小
  - 在大型软件代码中硬编码数据大小会是一种噩梦

*动态内存分配方式的分类*
- *显式分配*(explicit allocation)
  - 要求应用显式地释放任何已分配的块，例如`malloc`，`free`
- *隐式分配*(implicit allocation)
  - 编译器/运行时库自动释放未使用的已分配的块
  - 隐式分配器称为垃圾收集器（Garbage Collector），比如Java

*堆和栈的内存分配*
- 分配方式：动态内存分配
  - 栈由*编译器*管理：隐式分配
  - 堆的分配和释放由*程序员*管理：显式分配
- 分配大小
  - 栈是由高地址向低地址生长的数据结构，是一块连续的内存，能从栈中获得的内存*较小*，编译期间确定大小
  - 堆是由低地址向高地址生长的数据结构，是一个不连续的储存空间，内存获取比较灵活，也*较大*

*动态内存分配函数`malloc()`*
- `malloc()`函数: `void * malloc (size_ t size);`
  - 申请一块size大小的连续堆内存
  - 函数返回值是一个指针，指向刚分配的内存首地址
  - 如果申请内存失败， 返回一个空指针，即返回值为NULL
- 动态内存的分配和释放必须成对使用
  - 如果`malloc()`比`free()`多，会造成内存泄漏
  - 如果`malloc()`比`free()`少，会造成二次删除，破坏内存，导致程序崩溃
*动态内存回收函数`free()`*
- `free()`函数：`void free (void *ptr)`
  - 释放指针变量在堆区上的内存空间
  - 不能释放栈上的内存空间
  - `free()`要与`malloc()`成对使用

=== 连续内存分配

==== 动态分区分配

===== 连续内存分配

*连续内存分配*
- 操作系统在分配物理内存时，必须给应用程序分配一块地址连续、大小不小于所需空间的内存区域
  ```
  物理内存：
  |--------|-----------|-----------|-----------|
  |  OS    |   P1      |   P2      |   空闲区  |
  |--------|-----------|-----------|-----------|
  ```
  这里每个进程 P1、P2 都占据一段连续的物理地址空间

*内存碎片（Memory Fragmentation）*：当内存被动态地分配和释放时，可能出现未能有效利用的空闲区域，称为碎片
- *外碎片*：分配单元间未被使用内存
- *内碎片*：分配单元内部未被使用内存

===== 内存分配算法

*动态分区分配（Dynamic Partition Allocation）*
- 当程序被加载执行时或运行中数据存储时，分配一个进程指定*大小可变*的分区(内存块)
  - 分区的地址是连续的
  - 用户库/操作系统需要维护的*数据结构*
    - 已分配分区：已分配给应用的分区
    - 空闲分区(Empty-blocks)
- 设计要解决的问题
  #three-line-table[
    | 问题          | 含义          | 解决方法                         |
    | ----------- | ----------- | ---------------------------- |
    | *空闲块组织* | 如何记录和组织空闲块？ | 位图 / 空闲表 / 空闲链表              |
    | *放置位置*  | 如何选择合适的空闲块？ | 各种分配策略（First/Best/Worst Fit） |
    | *分割*    | 分配后剩余部分怎么办？ | 分割成已用 + 剩余空闲块                |
    | *合并*    | 释放后如何防止碎片？  | 合并相邻空闲块                      |
  ]
- 动态分区分配策略
  - 最先匹配(First-fit)
  - 最佳匹配(Best-fit)
  - 最差匹配(Worst-fit)
*最先匹配(First-fit)*
- 算法
  - 从空闲链表头开始扫描
  - 找到第一个足够大的空闲块
  - 分割并分配给进程
- 优点：
  - 实现简单
  - 分配速度快
  - 大块区域保留在高地址区
- 缺点：
  - 容易在低地址区形成碎片
  - 频繁分配/释放会导致外碎片增多
*最佳匹配(Best-fit)*
- 算法
  - 分配n字节分区时， 查找并使用不小于n的最小空闲分区
  - 释放分区时，检查是否可与临近的空闲分区合并
- 优点
  - 多数申请分配的尺寸较小时
  - 效果很好
- 缺点
  - 外碎片
  - 释放分区较慢
  - 容易产生很多无用的小碎片
*最差匹配(Worst-fit)*
- 算法
  - 分配n字节分区时， 查找并使用最大的空闲分区
  - 释放分区时，检查是否可与临近的空闲分区合并
- 优点
  - 中等大小的分配较多时，效果最好
- 缺点
  - 外碎片，释放分区较慢，容易破坏大的空闲分区

==== 伙伴系统(Buddy System)

*伙伴系统(Buddy System)的需求背景*
- 观察&分析
  - 基本的分配策略很简单和通用，但性能差，外碎片多
  - 内核和应用的内存*需求特征*
    - 内核经常以$2^U$个4KB大小来分配和释放连续地址的内存块
    - 需要能快速地分配和释放，且不会产生外碎片
- 需要新的连续内存分配策略

*伙伴系统的工作原理*
- 把整个物理内存分区成若干块（block），每个块的大小是$2^n$的幂次
  - 最小块：通常为一页（4KB）
  - 最大块：整块内存（如 1MB、1GB）
  - 任意内存块大小都满足：
    ```
    2^(i−1) < s ≤ 2^i
    ```
    则分配一个大小为$2^i$的块
  - 二叉树结构表示内存块
    - 每个节点代表一个空闲块
    - 每次分配时，若块太大则继续二等分
    - 每个被拆开的两个子块就是一对伙伴（Buddy）
*分区大小*
- 可分配分区的大小$2^U$
- 待分配分区的大小为$2^(U-1) < s ≤ 2^U$
  - 把整块分配给应用
- 待分配分区的大小为$s <= 2^(i-1)$
  - 将大小为$2^i$的当前空闲分区划分成两个大小为$2^(i-1)$的伙伴分区
  - 重复划分过程，直到找到合适大小的分区
*分配过程*
- 数据结构
  - 空闲块按大小和起始地址组织成二维数组
    - 示例（单位：KB）
      #three-line-table[
        | 块大小 | 空闲块起始地址列表         |
        | :--- | :--- |
        | 1K  | [512, 1024, 4096] |
        | 2K  | [2048, 8192]      |
        | 4K  | [0, 16384]        |
        | 8K  | [32768]           |
      ]
  - 初始状态：只有一个大小为$2^U$的空闲块
- 分配过程
  - 由小到大在空闲块中找最小可用块
  - 如空闲块过大，对可用空闲块进行二等分，直到得到合适可用空闲块
*释放过程*
- 释放过程
  - 把块放入空闲块数组
  - 合并满足条件的空闲块
- 合并条件
  - 大小相同$2^i$
  - 地址相邻
  - 低地址空闲块起始地址为$2^(i+1)$
*伙伴系统工作过程示例*
#figure(
  image("pic/2025-10-18-13-31-13.png", width: 80%),
  numbering: none,
)

=== 非连续内存分配

==== 非连续内存分配的概念

*非连续内存分配的需求背景*
- *碎片问题*
  - 内核通过页表能够*把多个地址不连续的物理页转换为地址连续的多个虚拟页*
  - 提供给应用程序和内核自身使用地址连续的虚拟内存块，这样可以比较轻松地解决*内存分配的碎片问题*
- *较大的内存空间*
  - 创建运行的程序时需要分配让其正常运行所需的*比较大的内存空间*
  - 程序运行时会需要动态申请和释放比较大的内存空间
  - 程序运行时会需要动态申请和释放比较大的内存空间
    - 通常用户库发出请求
    - 减少系统调用次数
    - 一次申请$2^U$MB大小(如:64MB)的内存

*非连续内存分配的设计目标*
- 提高内存利用效率和管理灵活性
  - 允许一个程序使用非连续的物理地址空间
  - 允许共享代码与数据
  - 支持动态加载和动态链接

*非连续分配需要解决的问题*
- 虚拟地址到物理地址的*地址转换*
  - 软件实现 （灵活，开销大）
  - 硬件实现 （够用，开销小）
- 非连续分配的*硬件辅助*机制
  - 如何选择非连续分配中内存块大小
  - 段式存储管理(segmentation)
  - 页式存储管理(paging)

==== 段式存储管理

*段式存储管理*：程序运行的段地址空间由多个段组成
- 主代码段、子模块代码段、公共库代码段、栈段、堆数据(heap)...
  #figure(
    image("pic/2025-10-18-13-42-09.png", width: 80%),
    numbering: none,
  )
- *段表*
  - 位于内存中
  - 由内核管理
  - 与任务/进程对应
  #figure(
    image("pic/2025-10-18-13-44-13.png", width: 80%),
    numbering: none,
  )
  - 每个*段表项（Segment Table Entry, STE）*通常包含两个重要信息：
    #three-line-table[
      | 字段名                   | 含义           | 说明      |
      | --------------------- | ------------ | ------- |
      | *段基址（Base Address）* | 段在物理内存中的起始地址 | 表示该段的起点 |
      | *段长度（Limit / Size）* | 段的大小（字节数）    | 用于越界检查  |
    ]
  - 在段式管理中，逻辑地址（Logical Address）被划分为两部分：
    ```
    逻辑地址 = [ 段号 | 段内偏移量 ]
    ```

==== 页式存储管理

*物理页面和逻辑页面*
- 物理页面（页帧、帧, Frame, Page Frame）
  - 把物理地址空间划分为大小相同($2^n$)的基本分配单位
- 虚拟页面（页面、页, Page）
  - 把虚拟地址空间也划分为相同大小的基本分配单位
  - 物理页面和虚拟页面的基本单位大小是相同的
- 虚拟页面到物理页面的对应
  - 虚拟地址到物理地址的地址转换
  - 硬件机制：页表/MMU/TLB
*页表*
- 位于内存中
- 由内核管理
- 与任务/进程对应

  #figure(
    image("pic/2025-10-18-13-50-50.png", width: 80%),
    numbering: none,
  )
  - CPU 产生的虚拟地址（Logical / Virtual Address）被分为两部分：
    ```
    虚拟地址 = [ 页号 (p) | 页内偏移 (o) ]
    ```
  - 页表（Page Table）
    - 虚拟页号 p → 物理页框号 f” 的映射关系
    - 页表项（Page Table Entry, PTE）
      #three-line-table[
        | 字段                      | 含义              |
        | ----------------------- | --------------- |
        | *物理页号 (Frame Number)* | 该虚拟页对应的物理页帧号    |
        | *存在位 (Present Bit)*   | 页是否在内存中（否则在磁盘）  |
        | *访问权限 (R/W/X)*        | 可读、可写、可执行权限     |
        | *修改标志 (Dirty Bit)*    | 是否被修改过          |
        | *访问标志 (Access Bit)*   | 是否被访问过，用于页面置换算法 |
      ]
  - 地址转换过程（MMU 执行）
    - CPU 发出虚拟地址 (p, o)
    - MMU 查找页表
      - MMU通过页表基址寄存器（Page Table Base Register, PTBR）找到当前进程页表在内存中的起始地址
      - 然后用页号 p 作为索引，查找对应的页表项（PTE）
    - 获取物理页帧号
    - 计算物理地址
    - 访问内存
  - 页式管理的特点与优点
    #three-line-table[
      | 特点               | 说明                 |
      | ---------------- | ------------------ |
      | *固定大小的页*       | 避免了外部碎片问题          |
      | *虚拟页到物理页映射*    | 允许物理页不连续           |
      | *地址转换由 MMU 实现* | 硬件完成映射             |
      | *每进程一张页表*      | 独立虚拟空间，互不干扰        |
      | *支持虚拟内存*       | 页不在内存时触发缺页异常，从磁盘调入 |
    ]
  - 页表带来的问题
    #three-line-table[
      | 问题      | 说明           | 解决方案                                    |
      | ------- | ------------ | --------------------------------------- |
      | 页表太大    | 32位地址需百万级页表项 | 使用*多级页表（Hierarchical Page Table）*     |
      | 地址转换速度慢 | 每次访问要先查页表再访存 | 使用*TLB（Translation Lookaside Buffer）* |
      | 页调度复杂   | 页可能被换出到磁盘    | 结合*缺页中断机制*与*页面置换算法（如LRU）*           |
    ]
- *页式存储管理面临的性能挑战*
  - 内存访问性能
    - 访问一个内存单元需要2次内存访问
      - 第一次访问：获取页表项
      - 第二次访问：访问数据
  - 页表大小
    - 页表可能非常大
- *提高页式存储管理性能的方法*
  - 缓存（Caching）
  - 间接（Indirection）访问
    #figure(
      image("pic/2025-10-18-14-01-05.png", width: 80%),
      numbering: none,
    )
*多级页表*
#figure(
  image("pic/2025-10-18-14-01-51.png", width: 80%),
  numbering: none,
)
- 对于每个进程都要保存一个页表，这是非常浪费的内存（尤其是当进程只使用很小一部分虚拟空间时）
- 只有用到的那部分虚拟地址空间才需要页表，没有用到的页，不为它建立页表结构——这就引出了多级页表
- *多级页表的地址转换*
  #figure(
    image("pic/2025-10-18-14-01-59.png", width: 80%),
    numbering: none,
  )
  - 举例：三级页表结构
    ```
    逻辑地址 = [p1 | p2 | p3 | o]
    ```
  - 多级页表的地址转换过程
    - CPU 生成逻辑地址
      ```
      虚拟地址 = [p1 | p2 | o]
      ```
    - 用 PTBR 找到一级页表
    - 用 p2 找到页表项
    - 组合生成物理地址
      ```
      物理地址 = (f, o)
      ```
    ```
    逻辑地址：[p1(10) | p2(10) | o(12)]
    PTBR → 一级页表[p1] → 二级页表[p2] → 得到物理页号 f
    物理地址 = (f, o)
    ```

*反置页表（Inverted Page Table, IPT）*：基于Hash映射值查找对应页表项中的物理页号
- 任务/进程id与页号的Hash值可能有冲突
- 页表项中包括保护位、修改位、访问位和存在位等标识
- #three-line-table[
    | 对比项  | 传统页表（如多级页表） | 反置页表（Inverted Page Table） |
    | ---- | ----------- | ------------------------- |
    | 建立方式 | 每个进程一个页表    | 所有进程共享一个全局页表              |
    | 表项数量 | 与虚拟页数成正比    | 与物理页数成正比                  |
    | 索引方式 | 按虚拟页号索引     | 通过哈希查找虚拟页对应物理页            |
    | 空间开销 | 大（虚拟页表太多）   | 小（与物理内存大小相关）              |
    | 查找效率 | 直接索引快       | 哈希查找需额外计算                 |
  ]
- 优势
  - 所有进程共享一个反置页表，省空间
  - 不需要多级页表转换，简化管理
- 劣势
  - 需要额外的数据结构，实现复杂
- *反置页表的地址转换*
  #figure(
    image("pic/2025-10-18-14-06-37.png", width: 80%),
    numbering: none,
  )
  - 反置页表的结构
    #three-line-table[
      | 字段             | 含义               |
      | -------------- | ---------------- |
      | *PID*        | 所属进程的标识符（进程ID）   |
      | *VPN (虚拟页号)* | 该物理页对应的虚拟页号      |
      | *控制位*        | 有效位、访问位、修改位、保护位等 |
      | *链指针（next）*  | 用于解决哈希冲突         |
    ]
  - 地址转换过程
    - CPU 产生虚拟地址
      ```
      VA = [ 页号 p | 页内偏移 o ]
      ```
      此时，CPU 还知道当前运行的进程 ID（PID）
    - 计算哈希值
      ```
      Index = Hash(PID, p)
      ```
    - 访问反置页表
      - 检查该项中的 PID 和 虚拟页号 (VPN) 是否与当前查询匹配
      - 若匹配成功，则找到对应的物理页帧号 f
      - 若不匹配，则说明发生了哈希冲突，需要继续沿着*链表指针（next）*查找下一个候选表项
    - 找到物理页帧号
      ```
      物理地址 PA = (f, o)
      ```
- *反置页表的hash冲突*
  #figure(
    image("pic/2025-10-18-14-06-43.png", width: 80%),
    numbering: none,
  )
  - 在反置页表中，不同 (PID, 页号) 可能经过哈希后映射到同一个索引槽，这就引发了哈希冲突（Hash Collision）
    - 计算哈希索引：
      ```
      Index = Hash(PID, 页号)
      ```
    - 索引表指向冲突链表的首地址：
      - 索引表第 0 项指向链表头 `0x18F1B`
    - 遍历冲突链表：
      - 第一个节点 (`PID=1, VPN=0xA63`)  不匹配
      - 跳转到 `next=0x18F1B`
      - 第二个节点 (`PID=0, VPN=0x1`)  匹配成功
    - 找到物理页帧号
      - 此表项对应物理页帧号 `PPN=0x18F1B`
    - 组合物理地址
      `PA = [PPN=0x18F1B | Offset=0x123]`
  - 为了加快查找，反置页表系统通常配合一个哈希索引表（Hash Table）：
    - 哈希表项数量较少
    - 每项存一个指针，指向链表头（解决冲突）
    - 表项指向反置页表中对应的页
    ```
    hash(pid, vpn) → 索引表[index] → 链表头 → 匹配表项
    ```


*段页式存储管理*
- 段式存储在内存保护方面有优势，页式存储在内存利用和优化转移到后备存储方面有优势
#figure(
  image("pic/2025-10-18-14-09-41.png", width: 80%),
  numbering: none,
)
- 两种机制的优缺点
  #three-line-table[
    | 类型       | 优点                          | 缺点                 |
    | -------- | --------------------------- | ------------------ |
    | *段式存储* | 按逻辑模块（代码段、数据段、栈段）划分，便于保护与共享 | 段大小不固定，易产生*外部碎片* |
    | *页式存储* | 页大小固定，无外部碎片，便于虚拟内存实现        | 不反映程序逻辑结构，不利于保护和共享 |
  ]
- 段页式系统将虚拟地址空间先按段划分，再对每个段按页划分
  #three-line-table[
    | 层次              | 含义                      |
    | --------------- | ----------------------- |
    | *段 (Segment)* | 代表一个逻辑单元（如代码段、数据段、堆、栈等） |
    | *页 (Page)*    | 每个段内部再按固定大小分页           |
    | *页帧 (Frame)*  | 物理内存按页帧划分，页→页帧映射        |
  ]
- 虚拟地址结构
  ```
  逻辑地址 = [ 段号 s | 页号 p | 页内偏移 o ]
  ```
- 地址转换过程
  - CPU 生成逻辑地址 `[s, p, o]`
  - 段表（Segment Table）
    - 每个进程都有自己的段表
    - 段表的起始地址保存在STBR（Segment Table Base Register）段表基址寄存器中
    - 用段号 s 作为索引，访问段表
  - 页表（Page Table）
    - 段表项提供了页表的基地址
    - 使用页号 p 作为索引，访问该段对应的页表项
    - 每个页表项包含对应页的物理页帧号 f
  - 形成物理地址
    ```
    物理地址 PA = [ f | o ]
    ```
==== 内存分配示例

*一个app调用malloc的例子*
```c
#include <stdlib.h>
int main(){
int *ptr;
ptr = malloc(15 * sizeof(*ptr)); /* a block of 15 integers */
    if (ptr != NULL) {
      *(ptr + 5) = 480; /* assign 480 to sixth integer */
      printf("Value of the 6th integer is %d",*(ptr + 5));
    }
}
```
- 第一步：OS加载程序运行
  #figure(
    image("pic/2025-10-18-14-26-56.png", width: 80%),
    numbering: none,
  )
- 第二步：程序发出malloc函数调用，且Lib库有空闲空间
  #figure(
    image("pic/2025-10-18-14-27-00.png", width: 80%),
    numbering: none,
  )
- 第二步：程序发出malloc函数调用，且Lib库无空闲空间
  #figure(
    image("pic/2025-10-18-14-27-04.png", width: 80%),
    numbering: none,
  )

#note(subname: [小结])[
  - 连续内存分配
    - 静态分配、动态分配（最先、最佳、最差）
    - 分配算法实例：伙伴系统
  - 非连续内存分配
    - 段式、页式、段页式
    - 页表：多级页表、反置页表
]

== 实践：建立地址空间的OS

https://rcore-os.cn/rCore-Tutorial-Book-v3/chapter4/index.html

#note(subname: [问题])[
  如何让应用程序编程不再考虑其运行时的起始执行地址问题？
  - 让每个程序都以为自己独占内存从地址 0 开始运行
    - MMU（Memory Management Unit） + 页表（Page Table）
    - CPU执行虚拟地址，而MMU把它翻译成物理地址
  - OS层面的意义
    - 操作系统通过：
      - 为每个进程建立独立页表
      - 在页表中配置虚拟页 → 物理页的映射关系
    - 即可让不同程序：
      - 在各自的虚拟空间中从地址0开始运行
      - 实际访问的物理内存不会冲突
      - 且彼此隔离（访问非法地址会触发 Page Fault）
]

=== 实验目标和步骤

==== 实验目标

实验目标
- 简化编程，APP不用考虑其运行时的起始执行地址
  - 与编译器达成共识，给每个APP设定一个固定起始执行地址
- 隔离APP访问的内存地址空间
  - 给APP的内存地址空间划界，不能越界访问OS和其他APP

实验要求
- 理解地址空间
- 掌握页机制
- 会处理页访问异常
- 会写支持页机制的操作系统

总体思路

#figure(
  image("pic/2025-10-21-16-41-21.png", width: 80%),
  numbering: none,
)

- 编译：应用程序和内核独立编译，合并为一个镜像
- 编译：不同应用程序可采用*统一的起始地址*
- 构造：系统调用服务，任务的管理与初始化
- 构造：建立基于*页表机制*的虚存空间
- 运行：特权级切换，任务与OS相互切换
- 运行：*切换地址空间*，跨地址空间访问数据

==== 实践步骤

*实践步骤*
- 修改APP的链接脚本(定制起始地址)
- 加载&执行应用
- 切换任务和任务的地址空间

*编译步骤*
```
git clone https://github.com/rcore-os/rCore-Tutorial-v3.git
cd rCore-Tutorial-v3
git checkout ch4
cd os
make run
```
#newpara()
*输出结果*
```
Into Test load_fault, we will insert an invalid load operation...
Kernel should kill this application!
[kernel] PageFault in application, bad addr = 0x0, bad instruction = 0x1009c, kernel killed it.

store_fault APP running...

Into Test store_fault, we will insert an invalid store operation...
Kernel should kill this application!
[kernel] PageFault in application, bad addr = 0x0, bad instruction = 0x1009c, kernel killed it.
power_3 [130000/300000]
```
#newpara()

*测试应用*
其中包含两个应用程序`04load_fault, 05store_fault`
```rust
// usr/src/bin/04load_fault.rs
......
    unsafe {
        let _i=read_volatile(null_mut::<u8>());
    }

// usr/src/bin/05store_fault.rs
......
    unsafe {
       null_mut::<u8>().write_volatile(1);
    }
```

=== 系统架构

==== 代码结构

*软件架构*
- 简化应用
- 建立Paging
- 内核页表
- 应用页表
- 信息传递
- 跳板机制
- 扩展TCB
- 扩展异常

*构建应用*
```
└── user
    ├── build.py(移除：给应用设定唯一起始地址的脚本)
    └── src（用户态库和应用程序）
        ├── bin（各个应用程序）
        ├── ...
        └── linker.ld(修改：将所有应用放在各自地址空间中固定的位置)
```

#newpara()

*地址空间*
```
├── os
    └── src
         ├── config.rs(修改：新增一些内存管理的相关配置)
         ├── linker-k210.ld(修改：将跳板页引入内存布局)
         ├── linker-qemu.ld(修改：将跳板页引入内存布局)
         ├── loader.rs(修改：仅保留获取应用数量和数据的功能)
         ├── main.rs(修改)
```
#newpara()
*mm子模块*
```
├── os
    └── src
         ├── mm(新增：内存管理的 mm 子模块)
             ├──address.rs(物理/虚拟 地址/页号的 Rust 抽象)
             ├──frame_allocator.rs(物理页帧分配器)
             ├──heap_allocator.rs(内核动态内存分配器)
             ├──memory_set.rs(引入地址空间 MemorySet 及逻辑段 MemoryArea 等)
             ├──mod.rs(定义了 mm 模块初始化方法 init)
             └──page_table.rs(多级页表抽象 PageTable 以及其他内容)
```
#newpara()
*改进OS*
```
├── os
    └── src
         ├── syscall
             ├──fs.rs(修改：基于地址空间的 sys_write 实现)
         ├── task
             ├──context.rs(修改：构造一个跳转到不同位置的初始任务上下文)
             ├──mod.rs(修改)
             └──task.rs(修改)
         └── trap
             ├── context.rs(修改：在 Trap 上下文中加入了更多内容)
             ├── mod.rs(修改：基于地址空间修改了 Trap 机制)
             └── trap.S(修改：基于地址空间修改了 Trap 上下文保存与恢复汇编代码)
```

==== RISC-V SV39页机制

RISC-V 支持多种分页模式（Sv32、Sv39、Sv48、Sv57），其中 Sv39 是目前 64 位操作系统最常用的分页模式
#three-line-table[
  | 模式   | 适用架构 | 虚拟地址位数 | 物理地址位数 | 页表级数 |
  | ---- | ---- | ------ | ------ | ---- |
  | Sv32 | RV32 | 32     | 34     | 2    |
  | Sv39 | RV64 | 39     | 56     | 3    |
  | Sv48 | RV64 | 48     | 56     | 4    |
]
Sv39 名称含义：使用 39 位虚拟地址。

*RISC-V 基于SATP的虚拟内存系统*
- 虚拟地址将内存划分为固定大小的页来进行地址转换和内容保护
- 页表基址寄存器satp：内核态控制状态寄存器控制了分页。satp 有三个域：
  - MODE 域：开启分页并选择页表级数
  - ASID（Address Space Identifier，地址空间标识符）域：可选的，用来降低上下文切换的开销
  - PPN 字段：保存了根页表的物理地址
  #three-line-table[
    | 位       | 字段名      | 含义                                    |
    | ------- | -------- | ------------------------------------- |
    | 63 – 60 | *MODE* | 地址转换模式（Sv39 = 8，Bare = 0）             |
    | 59 – 44 | *ASID* | 地址空间标识符 (Address Space ID)            |
    | 43 – 0  | *PPN*  | 根页表（一级页表）的物理页号 (Physical Page Number) |
  ]

*页表基址寄存器satp*
- satp CSR:(S-Mode) Supervisor Address Translation and Protection，监管者地址转换和保护
- 控制硬件分页机制

*初始化&使能页机制*
- M模式的RustSBI在第一次进入S-Mode之前会把0写入satp，以禁用分页
- 然后S-Mode的OS在初始化页表后会再次写satp
  - 使能页表:`MODE=8`
  - 设定页表起始物理地址页号 PPN
- MODE 域
  #three-line-table[
    | MODE 值 | 含义               |
    | ------ | ---------------- |
    | 0      | Bare（不分页，直接物理寻址） |
    | 8      | Sv39 模式（三级页表）    |
    | 9      | Sv48 模式（四级页表）    |
  ]
- ASID 域
  - ASID (Address Space ID) 用于区分不同进程的地址空间
  - 它让不同进程的虚拟页可以共存于 TLB
  - 避免了每次上下文切换都清空 TLB 的代价
- PPN 域
  - 表示根页表所在物理页号
  - 即 OS 初始化页表后，将其物理页帧号写入 satp.PPN
  - CPU 根据它访问第一级页表
- Sv39 地址结构与页表级联
  - 拟地址（Virtual Address）共 39 位，被划分为：
  ```
  [VPN[2] | VPN[1] | VPN[0] | offset]
  ```
  #three-line-table[
    | 字段     | 位数 | 含义           |
    | ------ | -- | ------------ |
    | VPN[2] | 9  | 一级页表索引       |
    | VPN[1] | 9  | 二级页表索引       |
    | VPN[0] | 9  | 三级页表索引       |
    | offset | 12 | 页内偏移（4 KiB页） |
  ]

*页表项（PTE）结构*
- 每个页表项（Page Table Entry）是 64 bit（8 字节）：
  #three-line-table[
    | 位       | 名称           | 含义             |
    | ------- | ------------ | -------------- |
    | 0       | V (Valid)    | 页表项是否有效        |
    | 1       | R (Read)     | 是否可读           |
    | 2       | W (Write)    | 是否可写           |
    | 3       | X (Execute)  | 是否可执行          |
    | 4       | U (User)     | 是否允许 U 模式访问    |
    | 5       | G (Global)   | 是否全局有效（跨 ASID） |
    | 6       | A (Accessed) | 是否被访问过（硬件置位）   |
    | 7       | D (Dirty)    | 是否被写过（硬件置位）    |
    | 9 – 8   | RSW          | 软件保留位          |
    | 53 – 10 | PPN          | 物理页帧号          |
    | 63 – 54 | 保留           | \                |
  ]
  - PTE 的含义判断
    - 若 (R/W/X) 全为 0 且 V=1 → 该项指向下一级页表
    - 若 (R/W/X) 任一为 1 → 该项为叶子节点，映射一页物理内存
    - 若 V=0 → 该项无效，触发 Page Fault

*页机制的启用过程（以 OS 初始化为例）*
- 禁用分页（M 模式阶段）
  - RustSBI 启动时，satp.MODE = 0
  - 此时所有访问为直接物理寻址
- OS 初始化阶段（S 模式）
  - 分配并初始化三级页表
  - 为内核代码段/数据段/栈建立虚拟映射
  - 将页表根地址写入 satp
  - 执行 sfence.vma 刷新 TLB
  - 分页机制正式启用

=== 用户视角的地址空间

==== ASOS地址空间

*应用程序的地址空间*
- *地址空间*：一系列*有关联*和*不一定连续*的逻辑段
- 由若干逻辑段组成的虚拟/物理内存空间与一个运行的程序（目前把一个运行的程序称为*任务*和*进程*）绑定
- 进程对代码和数据的直接访问范围限制在它关联的地址空间之内
- 应用地址空间和内核地址空间
  #three-line-table[
    | 空间类型                              | 描述                                             |
    | --------------------------------- | ---------------------------------------------- |
    | *用户地址空间 (User Address Space)*   | 供应用访问；由编译器生成逻辑地址，经过页表映射到物理页。应用程序只能访问自己这一套虚拟地址。 |
    | *内核地址空间 (Kernel Address Space)* | 供内核代码访问。内核可以访问系统的所有物理页，也包括自己的代码、数据、栈、页表等。      |
  ]

==== 跳板页

*跳板页（Trampoline Page）的设计动机*
- 当应用程序执行 ecall（或触发中断/异常）时：
  - CPU 从 用户态（U-mode） 进入 内核态（S-mode）
  - 需要跳转到一段内核汇编代码执行，这段代码就是 `_all_traps`
  - 但在跳转的瞬间：
    - 当前的页表仍是用户页表
    - 栈指针 `sp` 仍指向用户空间栈
    - 若直接访问内核数据结构（例如陷入上下文区），会触发 Page Fault
- 因此需要一种*“安全缓冲区”*：
  - 在用户页表和内核页表中都能访问，且虚拟地址一致的区域

  #figure(
    image("pic/2025-10-22-23-22-23.png", width: 80%),
    numbering: none,
  )

*跳板页 (Trampoline Page)*
- 放置在虚拟空间的固定高地址（例如：`TRAMPOLINE = 0xFFFF_FFFF_FFFF_F000`）
- 该页在所有进程的用户页表和内核页表中都映射到同一个物理页
- 物理页中存放的就是 `trap.S` 中的 `_all_traps`和`_restore` 例程（陷入(Trap)上下文页）
  #three-line-table[
    | 名称           | 功能                        |
    | ------------ | ------------------------- |
    | `_all_traps` | Trap 入口：保存用户态寄存器到陷入上下文页   |
    | `_restore`   | Trap 返回：从陷入上下文恢复寄存器并回到用户态 |
  ]

*基于跳板页的平滑过渡*：陷入（Trap）时的两个转换
- 当用户态 → 内核态发生 Trap 时，CPU 实际上经历了 两个转换：
  #three-line-table[
    | 类型         | 说明                            |
    | ---------- | ----------------------------- |
    | *特权级转换*  | 从 U-mode → S-mode（由 CPU 硬件完成），产生异常/中断时，CPU会跳到跳板页的`_all_traps`入口 |
    | *地址空间转换* | 从用户页表 → 内核页表（由 OS 手动完成），在切换页表后，可平滑地继续执行内核代码       |
  ]

*`sscratch` 的角色变化*
- 回顾：没有页机制的OS
  - 陷入上下文保存在内核栈顶，`sscratch`保存应用的内核栈
  - CPU 自动交换 sscratch 和 sp 的值
    - 只通过sscratch寄存器中转*用户/内核的栈指针*
    - 当一个应用 Trap 到内核时，sscratch 已指向该应用的内核栈栈顶，用一条指令即可从用户栈切换到内核栈，然后直接将 Trap 上下文压入内核栈栈顶
- 对比使能页机制的OS
  - 如何只通过sscratch寄存器中转栈指针和页表基址？
    - 方案1：通过sscratch寄存器中转*用户/内核的栈指针*
    - 方案2：通过sscratch寄存器中转*用户栈指针/页表基址*

*三种方案的演进与对比*
- 方案 1：通过 sscratch 中转 用户栈 ↔ 内核栈指针
  - 通过sscratch寄存器中转用户/内核的栈指针
    - 当前sp指针指向的是内核地址空间
    - 而此时页表还是用的用户态页表
  - 导致在内核态产生异常，*系统崩溃*
- 方案 2：sscratch 保存 用户栈指针 + 页表基址
  - 通过sscratch寄存器中转*用户栈指针/页表基址*
  - 当前用的是内核态页表，访问内核地址空间
  - 接下来需要取得应用的内核栈指针来把用户态当前的通用寄存器保存到陷入上下文中
  - 获取内核栈指针需要修改（*破坏*）通用寄存器才能完成，无法*正确保存*
- 方案 3（最终方案）：sscratch 保存“陷入上下文地址”
  - 通过sscratch进行应用的用户态栈指针$<->$陷入上下文地址切换（中转）
  - 保存用户态寄存器到陷入上下文
  - 读出陷入上下文中的页表基址/应用的内核栈指针/`trap_handler`地址
  - 切换页表，跳转`trap_handler`

  ```
  用户地址空间 (User Page Table)
  ┌──────────────────────────────┐
  │ 用户代码 / 数据 / 栈          │
  │------------------------------│
  │ TrapContext (共享页)          │ ← 用户页表 & 内核页表同时映射
  │------------------------------│
  │ Trampoline Page (跳板页)      │ ← 所有任务共享，执行 trap.S
  └──────────────────────────────┘


  内核地址空间 (Kernel Page Table)
  ┌──────────────────────────────┐
  │ ...                          │
  │ Kernel Stack                 │ ← 每个任务一个
  │------------------------------│
  │ TrapContext (同一物理页)     │ ← 与用户页表共享物理页
  │------------------------------│
  │ Trampoline Page              │ ← 同一物理页，统一入口
  └──────────────────────────────┘
  ```

==== 应用的地址空间

*应用程序设计*
- 应用程序
  - 内存布局有调整
- 没有更新
  - 项目结构
  - 应用代码
  - 函数调用
  - 系统调用

*应用程序的内存布局*
- 由于每个应用被加载到的位置都相同，所以它们共用一个链接脚本 `linker.ld`
- `BASE_ADDRESS = 0x10000`

=== 内核管理地址空间

==== 管理物理内存

*从内核角度看地址空间*
- 理解地址空间
- 理解陷入上下文页
*内核如何“理解”地址空间*
- 在开启分页（MMU）后，整个内存的三个世界：
  #three-line-table[
    | 视角   | 空间       | 描述              |
    | ---- | -------- | --------------- |
    | 用户空间 | 虚拟地址空间   | 每个进程独立的页表映射     |
    | 内核空间 | 虚拟地址空间   | 共享内核页表（访问所有物理页） |
    | 物理空间 | RAM 实体地址 | 全局唯一的真实内存       |
  ]
- 内核理解地址空间
  - 建立&感知虚拟/物理地址
  - 在内核/应用虚拟地址空间之间穿越
- 应用的页表
  - 代表了内核管理下的现实情况下的应用地址空间
  - 让CPU"能看"到的应用地址空间”
  - 页表机制
    - 管理物理内存
    - 建立内核/应用页表
    - 使能页机制

*从内核视角看物理内存布局（例：RISC-V QEMU 8MB RAM）*
- 物理内存 = 一整块连续的 RAM（假设 8MB）
  #three-line-table[
    | 区域                          | 地址范围                         | 说明                      |
    | --------------------------- | ---------------------------- | ----------------------- |
    | *0x80000000 – 0x80200000* | 内核代码 (.text)、数据 (.data/.bss) | 由链接脚本 `linker.ld` 定义    |
    | *0x80200000 – ekernel*    | 内核动态分配区（堆、管理结构）              |          \               |
    | *ekernel – 0x80800000*    | 空闲物理页帧                       | 可分配给应用、页表、TrapContext 等 |
  ]
- 物理内存(RAM 设定位8MB)，包括：
  - 应用/内核的数据/代码/栈/堆
  - 空闲的空间
  - 特别是各种管理类数据
    - 任务控制块
      - MemorySet
        - 应用/内核的多级页表等
      - 应用核心栈
      - 应用的TrapContext页 ....
- 因此，物理内存的使用状态可以分为三类：
  #three-line-table[
    | 类型        | 举例                   | 管理者       |
    | --------- | -------------------- | --------- |
    | 已使用（内核自用） | 内核代码、数据、堆            | 链接脚本定义    |
    | 已使用（应用用）  | 应用页表、用户页、TrapContext | 由 OS 分配   |
    | 空闲（未使用）   | 剩余页帧                 | 内核的物理页分配器 |
  ]
- *管理物理内存*
  - 物理内存上已经有*一部分*用于放置内核的代码和数据
  - 需要将*剩下的空闲内存*以单个物理页帧为单位管理起来
    - 当需要存应用数据或扩展应用的多级页表时*分配*空闲的物理页帧
    - 在应用出错或退出的时候*回收*应用占的所有物理页帧
  - 采用连续内存的动态分配策略
  - 分配/回收物理页帧的接口
    - 提供`alloc()`和`dealloc()`函数接口
*物理页帧（Physical Page Frame）的管理单元*
- 页帧 (Page Frame) 是操作系统进行物理内存管理的最小单位
  - 页帧大小固定为 4KB
  - 每个页帧由一个页号（PPN）标识；
  - 内核通过「页帧分配器」来记录哪些页帧空闲、哪些被使用
  ```
  物理地址空间：
  ┌────────────────────┐ 0x80800000 (8MB)
  │       空闲页帧     │  ← alloc() 申请
  │--------------------│
  │ TrapContext 页     │
  │ 应用页表           │
  │ 应用数据/代码页    │
  │--------------------│
  │ 内核堆/内核栈      │
  │--------------------│
  │ 内核数据段 .data   │
  │--------------------│
  │ 内核代码段 .text   │
  └────────────────────┘ 0x80000000
  ```

==== 建立内核/应用页表

*SV39多级页表*
- SV39 多级页表是以页大小的节点为单位进行管理。每个节点恰好存储在一个物理页帧中，它的位置可以用一个物理页号来表示
  #three-line-table[
    | 属性     | 值                       |
    | ------ | ----------------------- |
    | 虚拟地址宽度 | 39 位                    |
    | 物理地址宽度 | 56 位（44 位 PPN + 12 位偏移） |
    | 页大小    | 4 KB                    |
    | 每级页表项数 | 512 (2⁹)                |
    | 级数     | 3 级（L2-L1-L0）           |
  ]
- satp CSR 寄存器用于管理当前进程的页表基址

*建立内核/应用页表*
- 页表起始物理地址
- 页表内容:虚地址<->物理地址映射
  - *恒等映射 Identical Mapping*
    - 内核自己通常使用恒等映射
      - 内核的 .text, .data, .rodata, .bss
      - 内核堆
      - 外设映射区（UART0, PLIC 等）
    - 这样做的好处：
      - 访问内核数据和指令时不需要复杂的映射
      - 简单可靠
      - 内核启动早期调试方便
  - 随机映射 Framed Mapping
    - 用户应用的虚拟地址空间一般是从 `0x0000_0000` 开始，而它的数据、代码、栈等分配在物理内存的不同页帧中
    #three-line-table[
      | 虚拟页         | 物理页        | 映射类型          |
      | ----------- | ---------- | ------------- |
      | 0x00400000  | 0x80501000 | 应用代码          |
      | 0x00401000  | 0x80502000 | 应用数据          |
      | 0x00800000  | 0x80503000 | 应用用户栈         |
      | 0xFFFF_F000 | 0x80504000 | TrapContext 页 |
    ]
    这种「虚拟页号 (VPN) → 物理页号 (PPN)」映射由 OS 通过修改页表项实现
    - VPN: Virtual Page Number
    - PPN: Physical Page Number
    - satp: 包含页表起始处PPN的CSR
  #three-line-table[
    | 模式                           | 含义           | 场景            |
    | ---------------------------- | ------------ | ------------- |
    | *恒等映射 (Identical Mapping)* | 虚拟地址 == 物理地址 | 内核段映射、设备寄存器映射 |
    | *随机映射 (Framed Mapping)*    | 虚拟地址 ≠ 物理地址  | 应用代码/数据映射     |
  ]

*建立和拆除虚实地址映射关系*

- 在多级页表中找到一个虚拟地址对应的*页表项*。
- 通过*修改页表项*的内容即可完成*键值对*的插入和删除，从而实现*映射关系*的建立和拆除
- 插入映射：
  - 解析虚拟地址 → VPN2, VPN1, VPN0
  - 从根页表开始查找
  - 若中间节点存在，继续往下找
  - 若中间节点不存在，分配新的页帧
  - 填入最终 PTE（写入物理页号 + 权限位）
- 删除映射：
  - 找到该虚拟页的页表项
  - 将该项的 V 位清零
  - 如果上层页表空了，递归释放页帧

*内核/应用页表的建立过程：使能页机制*
- 内核页表建立
  - 内核启动时创建一张全局页表，用于：
    - 恒等映射内核地址区
    - 映射外设
    - 映射 trampoline 页
  - 步骤：
    - 分配一页作为 root 页表
    - 恒等映射内核的 .text/.data/.bss/.heap 段
    - 恒等映射外设（UART、PLIC、CLINT）
    - 建立 trampoline 映射
    - 写入 satp 并开启分页 `satp = root_ppn`
- 应用页表建立
  - 每个应用在加载时，创建独立页表
  - 内容包括：
    - 应用的代码段、数据段
    - 用户栈
    - TrapContext 页
    - trampoline 页（共享）
  - 这些页表项通过内核分配的物理页帧建立
- 核心数据结构的包含关系
  ```
  Task Control Block (TCB)
      └── MemorySet (表示整个虚拟地址空间)
            ├── PageTable (页表对象)
            │      └── root_ppn (根页表的物理页号)
            ├── 映射区域 (MapArea)
            │      ├── VPN区间 → PPN区间映射
            │      └── 权限信息 (R/W/X/U)
            └── 数据结构封装 add_area(), remove_area()
  ```

==== 管理地址空间

*应用地址空间*
#figure(
  image("pic/2025-10-23-14-04-53.png", width: 80%),
  numbering: none,
)

*从“理想地址空间”到“现实页表”的映射*

#three-line-table[
  | 概念                        | 含义               | 举例                       |
  | ------------------------- | ---------------- | ------------------------ |
  | *逻辑段 (Logical Segment)* | 程序逻辑上连续的一块虚拟地址空间 | 代码段、数据段、堆、栈、TrapContext页 |
  | *地址空间 (Address Space)*  | 一个任务（进程）所有逻辑段的集合 | 应用完整的虚拟地址视图              |
  | *页表 (Page Table)*       | 地址空间的物理实现方式      | 把每个虚拟页映射到物理页             |
]
- 编译器和链接器看到的是逻辑段
- CPU 和 MMU 操作的是页表
- 操作系统用数据结构（`MapArea + MemorySet`）把两者连接起来

*逻辑段*
- 逻辑段：内核/应用会用到的一段连续地址的虚拟内存
- 内核/应用运行的虚拟地址空间：由多个逻辑段组成

*逻辑段的数据结构`MapArea`*
- 逻辑段是操作系统中最小的“连续虚拟地址管理单元”
- 它描述了一段虚拟地址区间，以及它的映射方式、权限、物理页帧信息
  ```rust
  // os/src/mm/memory_set.rs

  pub struct MapArea {
      vpn_range: VPNRange, //一段虚拟页号的连续区间
      data_frames: BTreeMap<VirtPageNum, FrameTracker>,//VPN<-->PPN映射关系
      map_type: MapType,  //映射类型
      map_perm: MapPermission, //可读/可写/可执行属性
  }
  ```
  #three-line-table[
    | 字段            | 类型                            | 作用                                  |
    | ------------- | ----------------------------- | ----------------------------------- |
    | `vpn_range`   | 连续的虚拟页号范围                     | 描述该逻辑段所覆盖的虚拟页范围                     |
    | `data_frames` | `BTreeMap<VPN, FrameTracker>` | 保存该逻辑段内每个虚拟页对应的物理页帧                 |
    | `map_type`    | `MapType`                     | 映射方式：恒等 (Identical) 或 框架映射 (Framed) |
    | `map_perm`    | `MapPermission`               | 权限：可读 R / 可写 W / 可执行 X / 用户态 U      |
  ]

*地址空间的数据结构 MemorySet*
- 地址空间：一系列有关联的不一定连续的逻辑段
- 它由多个逻辑段 (MapArea) 组成，并维护一张多级页表
  ```rust
  // os/src/mm/memory_set.rs

  pub struct MemorySet {
      page_table: PageTable, //页表
      areas: Vec<MapArea>, //一系列有关联的不一定连续的逻辑段
  }
  ```
  #three-line-table[
    | 字段           | 作用                           |
    | ------------ | ---------------------------- |
    | `page_table` | 管理虚拟页与物理页映射关系的多级页表对象         |
    | `areas`      | 保存当前地址空间中所有逻辑段（如代码段、数据段、栈段等） |
  ]

*地址空间的管理时机（内核行为）*
- 操作系统管理的地址空间 `MemorySet=PageTable+MapArea`
- 内核在任务生命周期中，不断创建、切换、释放 `MemorySet`：
  #three-line-table[
    | 时机             | 内核行为                        | 说明                     |
    | -------------- | --------------------------- | ---------------------- |
    | *任务创建*       | 创建任务的 MemorySet             | 为任务分配独立的页表和逻辑段         |
    | *任务退出*       | 销毁任务的 MemorySet             | 回收页帧、释放页表              |
    | *内核/用户切换*    | 切换页表 (`satp`)               | 让 CPU 使用不同地址空间         |
    | *任务扩展内存*     | 修改 MemorySet                | 例如 `mmap`、`sbrk` 等系统调用 |
    | *Trap/返回用户态* | 映射 TrapContext、Trampoline 页 | 让用户/内核共享关键页            |
  ]

*新建任务的 `MemorySet` 过程*
- 创建新的页表
  - 分配一个空物理页帧作为 root 页表
- 创建逻辑段向量 (areas)
  - 从 ELF 文件中解析 .text、.data、.bss 段
  - 为每个段创建一个 MapArea
  - 映射到物理页（Framed 模式）
  - 填写相应的权限（R/W/X/U）
- 加入 TrapContext 与 Trampoline 页
  - TrapContext 页是每任务独有
  - Trampoline 页是所有任务共享（恒等映射）
*在地址空间插入/删除一个逻辑段*
- 更新页表中的相应页表项
- 更新逻辑段对应的物理页帧内容

=== 实现ASOS （Address Space Operating System）

==== 启动分页模式

*对分时共享多任务操作系统的扩展*
- 创建*内核页表*，使能分页机制，建立内核的虚拟地址空间
- 扩展*Trap上下文*，在保存与恢复Trap上下文的过程中切换页表（即切换虚拟地址空间）
- 建立用于内核地址空间与应用地址空间相互切换所需的*跳板空间*
- 扩展*任务控制块*包括虚拟内存相关信息，并在加载执行创建基于某应用的任务时，建立应用的虚拟地址空间
- 改进Trap处理过程和sys_write等*系统调用*的实现以支持分离的应用地址空间和内核地址空间

*启动分页模式*
- 创建内核地址空间
- 内存管理子系统的初始化
*创建内核地址空间的全局实例*
- 内核地址空间`KERNEL_SPACE`
  ```rust
  pub static ref KERNEL_SPACE: MemorySet = MemorySet::new_kernel()
  ```
*内存管理子系统的初始化*
- 把空闲物理内存按照堆(heap)进行动态连续内存管理初始化
- 基于堆实现物理页帧分配管理初始化
- 设置satp，启动分页机制，激活内核地址空间`KERNEL_SPACE`
  ```rust
  // os/src/mm/mod.rs
  pub fn init() {
      heap_allocator::init_heap();
      frame_allocator::init_frame_allocator();
      KERNEL_SPACE.exclusive_access().activate();
  }
  ```

==== 实现跳板机制

*实现跳板机制的动机*
- 在启动分页机制后，让处于不同地址空间的应用和内核能够进行正常的*特权级切换操作和数据交互*
*跳板机制的思路*
- 内核和应用的虚拟地址空间中*最高的虚拟页面*是一个跳板(trampoline)页
- 在*特权级*切换后，要迅速完成*地址空间*切换，*内核栈*切换，并*平滑地继续执行内核代码*
- 应用地址空间的*次高虚拟页面*被设置为存放应用的 Trap 上下文
  #note(subname: [问题])[
    为何不直接把Trap上下文仍放到应用的内核栈中呢？
    - 访问内核栈中的Trap上下文地址，需要先切换页表
    - 页表信息放在 Trap上下文中，形成了相互依赖
  ]
*建立跳板页面*
- 将 trap.S 中的整段汇编代码放置在 .text.trampoline 段，并在调整内存布局的时候将它对齐到代码段的一个页面中
  ```rust
  # os/src/linker.ld
  stext = .;
      .text : {
      *(.text.entry)
      . = ALIGN(4K);
      strampoline = .;
      *(.text.trampoline);
      . = ALIGN(4K);
      *(.text .text.*)
  }
  ```
*扩展Trap 上下文数据结构*
- ```rust
  // os/src/trap/context.rs
  pub struct TrapContext {
      pub x: [usize; 32],
      pub sstatus: Sstatus,
      pub sepc: usize,
      pub kernel_satp: usize, //内核页表的起始物理地址
      pub kernel_sp: usize,   //当前应用内核栈栈顶的虚拟地址
      pub trap_handler: usize,//内核中 trap handler 入口点的虚拟地址
  }
  ```
*切换Traps上下文*
- 保存Trap上下文
  - 把用户栈指针切换到用户地址空间中的TrapContext
  - 在TrapContext保存通用寄存器、sstatus、sepc
  - 在TrapContext读出kernel_satp、kernel_sp、trap_handler
  - 切换内核地址空间，切换到内核栈
  - 跳转到trap_handler继续执行
- 恢复Trap上下文
  - 上述过程的逆过程
  #note(subname: [问题])[
    为何用`jr t1`而不是`call trap_handler`完成跳转？
    - 在内存布局中，这条 .text.trampoline 段中的跳转指令和 trap_handler 都在代码段之内，汇编器（Assembler）和链接器（Linker）会根据 linker-qemu.ld 的地址布局描述，设定跳转指令的地址，并计算二者地址偏移量，让跳转指令的实际效果为当前 pc 自增这个偏移量
    - 这条跳转指令在被执行的时候，它的虚拟地址被操作系统内核设置在地址空间中的最高页面之内，所以加上这个偏移量并不能正确的得到 trap_handler 的入口地址
  ]
==== 加载和执行应用程序

*加载和执行应用程序*
- 扩展任务控制块
- 更新任务管理
*扩展任务控制块TCB*
- 应用的地址空间 memory_set
- Trap 上下文所在物理页帧的物理页号trap_cx_ppn
- 应用数据大小base_size
  ```rust
  // os/src/task/task.rs
  pub struct TaskControlBlock {
      pub task_cx: TaskContext,
      pub task_status: TaskStatus,
      pub memory_set: MemorySet,
      pub trap_cx_ppn: PhysPageNum,
      pub base_size: usize,
  }
  ```
*更新任务管理*
- 创建任务控制块TCB
  - 根据应用的*ELF执行文件*内容形成应用的虚拟地址空间
  - 建立应用转换到内核态后用的*内核栈*
  - 在内核地址空间建立应用的*TCB*
  - 在用户地址空间构造出一个*Trap上下文*TrapContext

==== 改进 Trap 处理的实现

*改进 Trap 处理的实现*
- 由于应用的 Trap 上下文不在内核地址空间，因此调用 current_trap_cx 来获取当前应用的 Trap 上下文的可变引用而不是像之前那样作为参数传入 trap_handler 。至于 Trap 处理的过程则没有发生什么变化。
- 为了简单起见，弱化了 S态 –> S态的 Trap 处理过程：直接 panic 。
  ```rust
  let restore_va = __restore as usize - __alltraps as usize + TRAMPOLINE;
  unsafe {
    asm!(
      "fence.i",
      "jr {restore_va}",
    )
  }
  ```

==== 改进 sys_write 的实现

*改进 sys_write 的实现*

- 由于内核和应用地址空间的隔离，sys_write不再能够直接访问*位于应用空间中的数据*
- 需要*手动查页表*才能知道那些数据被放置在哪些物理页帧上并进行访问

*访问应用空间数据的辅助函数*
- 页表模块 page_table 提供了将应用地址空间中一个缓冲区转化为在内核空间中能够直接访问的形式的辅助函数：
  ```rust
  // os/src/mm/page_table.rs
  pub fn translated_byte_buffer()
  ```
- 查找应用的页表，根据应用虚地址找到物理地址
- 查找内核的页表，根据物理地址找到内核虚地址
- 基于内核虚地址完成对应用数据的读写
