#import "@preview/scripst:1.1.1": *

= 进程管理与单处理器调度

== 进程管理

#note(subname: [问题])[

  如何定义进程管理的系统调用接口？
  - 功能需求、开发效率和执行效率

  操作系统中的*进程管理（Process Management）*主要通过一组系统调用（System Calls）来完成。这些接口是用户程序与内核之间的桥梁。

  #three-line-table[
    | 功能类别 | 典型系统调用                          | 说明           |
    | ---- | ------------------------------- | ------------ |
    | 进程创建 | `fork()`, `exec()`              | 创建新进程或装载新程序  |
    | 进程终止 | `exit()`, `kill()`              | 结束自身或其他进程    |
    | 进程控制 | `wait()`, `sleep()`, `getpid()` | 控制执行、等待子进程等  |
    | 进程通信 | `pipe()`, `shmget()`, `mmap()`  | 支持进程间通信（IPC） |
  ]
  这些系统调用构成了操作系统内核提供的“服务接口”，上层用户和应用程序通过它们进行进程的生命周期管理和调度交互。

  设计接口时的三大权衡
  - 功能需求（Functionality）
    - 系统调用接口需要提供足够的功能以支持
      - 创建与销毁进程
      - 进程状态转换（就绪、运行、阻塞等）
      - 进程间通信与同步（信号、管道、消息队列等）
      - 资源管理与访问控制
    - 要确保：
      - 接口语义清晰、可扩展性强
      - 支持并发、多任务与多用户环境
      - 满足不同类型程序（交互式、后台服务等）的需求
  - 开发效率（Development Efficiency）
    - 接口设计要考虑到：
      - 编程的简洁性与一致性
      - API 与内核实现的解耦
      - 调试与测试的便利性
  - 执行效率（Execution Efficiency）
    - 进程管理是操作系统最核心的功能之一，任何系统调用都伴随用户态与内核态的切换，因此要尽量减少：
      - 上下文切换的开销
      - 内核锁竞争
      - 调度器频繁唤醒的代价
    - 常见的优化策略包括：
      - 轻量级进程（LWP）或线程模型
      - 延迟创建（Lazy Fork）
      - 内核级调度队列的优化
]

=== 进程的基本概念

==== 进程管理的需求背景

*背景*
- 硬件越来越强大
  - 更快的CPU with MMU/TLB/Cache
  - 更大的内存和外存
  - 更丰富的外设
- 开发者希望能够在计算机上有更多的动态交互和控制能力
- 使用者需要更方便的计算机交互能力
*目标*
- 提高开发效率和执行效率
- 操作系统必须提供一种机制来动态地管理多个程序的运行状态与资源使用
*用户与开发者的需求*
- 开发者的期望：
  - 能够同时运行多个程序（并发）
  - 提高程序的开发与执行效率
  - 让系统在多个应用间灵活切换
- 使用者的期望：
  - 方便地操作计算机（CLI、GUI）
  - 能动态控制程序的运行：
    - 启动新程序
    - 暂停或停止现有程序
    - 同时执行多个任务

==== 进程的基本概念

引入*进程(Process)*概念的目的
- 清晰地*刻画操作系统*中程序运行的动态内在规律
- 有效*管理和调度*多个程序的执行和对资源的使用

*进程提供给应用程序的抽象*
- 从应用角度看，进程提供给应用程序的*关键抽象*
  - *独立的逻辑控制流*：好像自己的程序独占地使用处理器
  - *私有的地址空间*：好像自己的程序独占地使用内存系统
- 从实现角度看
  - 进程是操作系统建立程序运行中的过程管理相关的*数据结构*
  - 以及对数据结构的*动态操作过程*
- 从资源角度看，进程是程序执行中*占用资源的集合*
  - 共享资源 v.s. 独占资源
  - 处理器、时间
  - 内存、地址空间
  - 文件、I/O、...

*进程*
- 简单定义
  - 一个程序的执行过程
  - 一个执行中程序的实例
- 详细定义
  - 一个具有一定*独立功能*的程序在某*数据集合*上的一次*执行和资源使用的动态过程*
    - 通过读写数据来执行程序逻辑
    - 创建并执行新进程
    - 使用共享资源：文件等

*进程与任务*
- 从资源占用和执行过程两个方面分析
- 不同点：
  - 任务是这里提到的进程的初级阶段，不具有如下功能：
    - 进程可以在运行的过程中，创建子进程、用新的程序内容覆盖已有的程序内容
    - 进程成为程序执行过程中动态申请/使用/释放各种资源的载体
- 进程的动态功能可让程序的运行更加灵活
#three-line-table[
  | 比较维度 | 任务（Task）    | 进程（Process）   |
  | ---- | ----------- | ------------- |
  | 定义层次 | 程序执行的初级单位   | 程序执行的完整实例     |
  | 资源使用 | 通常不具备资源管理能力 | 可申请、释放、共享资源   |
  | 动态特性 | 执行逻辑固定      | 可创建子进程、替换程序内容 |
  | 代表意义 | 执行流         | 执行流 + 资源集合    |
]

=== 进程管理

==== 进程管理系统调用

*进程管理系统调用产生背景*
- 如何让应用*方便地动态执行其他应用*？
  - `process_id = execute(app_name)`？
- 如何让应用*了解其启动的其他应用是否结束*？
  - 被启动的其他应用 `exit(status)`？
  - 发起的主应用 `wait(process_id)`？
- 因此，操作系统必须提供一组标准接口，让用户程序能够：
  - 启动（创建）其他进程
  - 控制（等待）进程
  - 终止（退出）进程
  - 查询进程信息
- 于是各种OS(UNIX/Windows...)都设计出了类似上面的进程管理类的各种*系统调用*

*典型的进程管理系统调用（UNIX为例）*
#three-line-table[
  | 系统调用                                | 功能说明                               |
  | ----------------------------------- | ---------------------------------- |
  | `int fork()`                        | *创建*一个新进程（子进程），几乎完全复制父进程，返回子进程的 PID。 |
  | `int exec(char *file)`              | 在当前进程中*加载*一个新的程序文件并执行（覆盖旧内容）。        |
  | `int exit(int status)`              | *终止*当前进程，向父进程报告退出状态。                 |
  | `int waitpid(int pid, int *status)` | *等待*指定子进程退出，并获取退出状态。                 |
  | `int getpid()`                      | 返回当前进程的进程号（PID）。                   |
]
这些系统调用构成了进程生命周期的完整闭环

*进程管理系统调用示例分析*
- `getpid()`
  ```rust
  // usr/src/bin/hello_world.rs
  pub fn main() -> i32 {
      // 显示自己的PID
      println!("pid {}: Hello world from user mode program!", getpid());
      0  // 返回的退出码
  }
  ```
- `fork() + exec() + waitpid() + exit()`
  ```rust
  // usr/src/bin/forkexec.rs
  pub fn main() -> i32 {
      println!("pid {}: parent start forking ...", getpid());
      let pid = fork();  // 创建子进程
      if pid == 0 {
          // 子进程
          println!("pid {}: forked child start execing hello_world app ... ", getpid());
          exec("hello_world");  // 执行hello_world程序
          100
      } else {
          // 父进程
          let mut exit_code: i32 = 0;
          println!("pid {}: ready waiting child ...", getpid());
          assert_eq!(pid, wait(&mut exit_code)); //确认等待的子进程PID
          assert_eq!(exit_code, 0);  //确认退出码是0
          println!("pid {}: got child info:: pid {}, exit code: {}", getpid() , pid, exit_code);
          0
      }
  }
  ```
  执行结果
  ```
  Rust user shell
  >> forkexec
  pid 2: parent start forking ...
  pid 2: ready waiting child ...
  pid 3: forked child start execing hello_world app ...
  pid 3: Hello world from user mode program!
  pid 2:  got child info:: pid 3, exit code: 0
  Shell: Process 2 exited with code 0
  >> QEMU: Terminated
  ```

==== 进程控制块PCB

*进程控制块（PCB）*
#figure(
  image("pic/2025-10-29-01-30-44.png", width: 80%),
  numbering: none,
)
- *进程控制块（PCB, Process Control Block）是操作系统内核中用于描述和管理一个进程状态的核心数据结构。*
  - 它相当于操作系统为每个进程建立的“身份证 + 档案袋”
  - 系统中所有正在运行或等待的进程，都有一个对应的 PCB 存放在内核空间中
- *PCB的作用*
  - PCB的主要作用有三个：
    - 唯一标识进程（通过PID等标识）
    - 保存进程状态（寄存器值、CPU上下文、地址空间等）
    - 支持进程调度和切换（可暂停与恢复）
  - 当CPU要切换任务时，内核保存当前进程的PCB，之后再从中恢复
- *PCB的数据结构组成* 在代码中常称为 `TaskControlBlock` 或 TCB
  #three-line-table[
    | 分类           | 内容                        | 说明                   |
    | ------------ | ------------------------- | -------------------- |
    | *标识信息*     | 进程ID（pid）                 | 唯一标识进程               |
    | *状态信息*     | 运行状态（就绪/运行/阻塞）            | 决定是否可被调度             |
    | *CPU上下文信息* | 通用寄存器、PC（程序计数器）、SP（堆栈指针）等 | 用于进程切换时保存和恢复执行现场     |
    | *内存管理信息*   | 地址空间、页表指针等                | 描述进程可访问的内存区域         |
    | *进程层次关系*   | 父进程、子进程PID                | 用于构建进程树              |
    | *资源信息*     | 打开的文件表、I/O缓冲区             | 记录进程占用的系统资源          |
    | *退出码*      | 程序执行结果                    | 父进程通过 `waitpid()` 获取 |
  ]
- *进程控制块与系统结构的关系*
  - TaskManager（任务管理器）
    - 维护系统中所有进程的PCB列表
    - 负责创建、销毁、调度等操作
  - Processor（处理器结构）
    - 保存当前正在运行进程的引用（`current`）
    - 同时包含一个空闲任务上下文（`idle_task_ctx`）
  - 进程队列
    - 不同状态的进程按照就绪队列、阻塞队列等分类
    - 调度器根据策略选择下一个运行进程

*Shell执行命令的过程*
- OS 启动阶段
  - 内核启动，初始化基本环境
  - 创建第一个用户级进程 `initproc`（类似于 Linux 的 `/sbin/init`）
- 初始化用户进程
  - `initproc` 运行，执行 `fork+exec(user_shell)`
  - 创建 `user_shell` 子进程
  - 然后调用 `waitpid()` 等待子进程结束
- Shell 交互阶段
  - 用户在 `user_shell` 输入命令（如 “`forkexec`”）
  - Shell 调用 `fork+exec(forkexec)`
  - 等待 `forkexec` 执行结束
- 应用运行阶段
  - `forkexec` 调用 `fork+exec(hello_world)`
  - `hello_world` 运行，打印输出后 `exit(0)`
  - `forkexec` 收到退出码，`waitpid()` 返回
  - `user_shell` 收到退出信息，重新等待输入
形成一个完整的调用链：
```
OS kernel → initproc → user_shell → forkexec → hello_world
```
每一级进程的创建，都对应一次 PCB 的创建与管理。

*进程切换机制*
- 进程切换过程
  - *暂停*当前运行进程，从运行状态变成其他状态
  - *调度*另一个进程从就绪状态变成运行状态
- 进程切换的要求
  - 切换前，*保存*进程上下文
  - 切换后，*恢复*进程上下文

*进程生命周期*
```
创建（new）→ 就绪（ready）→ 运行（running）→ 阻塞（waiting）→ 终止（terminated）
```
- 进程切换
  - *暂停*当前运行进程，从运行状态变成其他状态
  - *调度*另一个进程从就绪状态变成运行状态
- 进程生命周期的信息
  - 寄存器 (PC, SP, …)
  - CPU状态
  - 内存地址空间

==== 进程创建和程序加载

*进程创建的两种机制*
- Windows：`CreateProcess()`
  - 在 Windows 系统中，进程创建和加载是通过 单一系统调用 `CreateProcess() `完成的
  - 它同时完成了进程的创建、内存空间初始化、程序加载以及线程启动
  - 创建时关闭所有在子进程里的文件描述符
    ```
    CreateProcess(filename, CLOSE_FD)
    ```
    避免冲突、保护资源
  - 创建时改变子进程的环境
    ```
    CreateProcess(filename, CLOSE_FD, new_envp)
    ```
    创建运行环境、隔离
- UNIX：`fork()` + `exec()`
  - Unix 将“创建进程”和“加载程序”分为两步：
    - `fork()`：创建一个与父进程几乎完全相同的子进程
      - parent(old PID), child(new PID)
    - `exec()`：让子进程“换上”一个新程序的映像
      - PID 不变
  #figure(
    image("pic/2025-10-29-01-44-24.png", width: 80%),
    numbering: none,
  )

*`fork()` 系统调用：复制父进程*
- `fork()` 创建一个新的进程（子进程），其几乎完全复制父进程：
  - 子进程拥有自己的 PID
  - 拥有独立的地址空间
  - 拷贝父进程的代码段、数据段、堆、栈
  - 拷贝父进程打开的文件描述符（引用相同的内核文件对象）
  - 复制父进程的所有CPU寄存器(有一个寄存器例外)
    - 系统调用的返回值`a0`
- 执行结果：
  - 父进程中 `fork()` 返回 子进程PID
  - 子进程中 `fork()` 返回 0
  - 错误时返回 -1
  - `fork()` 返回值可方便后续使用，子进程可使用getpid()获取PID
- 进程创建`fork()`的执行过程
  - 对于子进程而言，fork()是对父进程地址空间的一次复制过程
    #figure(
      image("pic/2025-10-29-01-50-25.png", width: 80%),
      numbering: none,
    )
  ```rust
  int pid = fork()；		// 创建子进程
  if(pid == 0) {			// 子进程在这里继续
      // Do anything (unmap memory, close net connections…)
      exec(“program”, argc, argv0, argv1, …);
  }
  ```
*`exec()` 系统调用：加载新程序*
- `exec()` 会用新程序的映像替换当前进程的地址空间
  - 原来的代码、数据、堆、栈都被清空并加载新程序
- 执行后：
  - 当前进程不再返回原程序
  - 原 PID 保持不变
  - 进程控制块（PCB）被更新为新程序的信息
  ```rust
  main()
  …
  int pid = fork();			// 创建子进程
  if (pid == 0) {			        // 子进程在这里继续
      exec_status = exec(“calc”, argc, argv0, argv1, …);
      printf(“Why would I execute?”);
  }  else if (pid > 0) {				// 父进程在这里继续
      printf(“Whose your daddy?”);
      …
      child_status = wait(pid);
  } else {
  { /* error occurred */ // (pid < 0)
  ```
*进程管理应用示例：`fork()`*
```c
int  main() {
     pid_t  pid;
      int  i;
      for  (i=0;  i<LOOP;  i++){
           /* fork  another  process  */
           pid = fork();
           if  (pid < 0) { /*error  occurred  */
                fprintf(stderr, “Fork Failed”);
                exit(-1);
           }
           else if (pid == 0) { /* child process */
            fprintf(stdout, “i=%d, pid=%d, parent  pid=%d\n”,I, getpid() ,getppid());
           }
      }
      wait(NULL);
      exit(0);
}
```
输出显示：
- 每个父进程可能再派生多个子进程
- 每个子进程继承父进程的环境
- 形成层次结构如图中：
  ```
  1166
  ├──1168
  │   └──1172
  ├──1167
  │   ├──1170
  │   │   └──1173
  │   └──1171
  └──1169
  ```
  这就是 Linux 下 `/proc` 目录中进程树关系的真实反映

==== 进程等待与退出

*父进程等待子进程：`wait()`*
- `wait()`系统调用用于父进程等待子进程的结束
  - 子进程结束时通过`exit()`向父进程返回一个值
  - 父进程通过`wait()`接受并处理返回值
  - 它的基本作用包括：
    - 阻塞父进程，直到某个子进程结束
    - 获取子进程退出状态码（exit code）
    - 释放子进程的 PCB（进程控制块）资源
- `wait()`系统调用的功能
  - 有子进程存活时，父进程进入等待状态，等待子进程的返回结果
  - 当某子进程调用`exit()`时，唤醒父进程，将`exit()`返回值作为父进程中`wait()`的返回值

*僵尸进程与孤儿进程*
- 僵尸进程（Zombie Process）
  - 定义：进程已执行完并调用了 `exit()`，但父进程尚未调用 `wait()` 回收其信息（PCB仍存在）。
    - 状态：Z (zombie)
    - PCB 中仅保留：PID、退出码、父进程指针
    - 原因：父进程未及时调用 `wait()`
    - 影响：长期存在会导致系统资源（PID 表）耗尽
  - 解决方式：
    - 父进程调用 `wait()`
    - 或者由系统信号机制（SIGCHLD）触发自动回收
    - 若父进程本身已退出 → 由 `init`（PID 1）接管并回收
- 孤儿进程（Orphan Process）
  - 定义：父进程已结束，但子进程仍在运行，成为孤儿进程
  - 孤儿进程由root进程负责等待并回收

*子进程退出：`exit()`*
- 当子进程执行完毕或主动调用 `exit(status)` 时，它将：
  - 关闭所有打开的文件
  - 释放占用的内存
  - 清理大部分内核数据结构
  - 将 status 保存到 PCB
  - 通知父进程
  - 将自身状态设为僵尸（zombie）
  - 等待父进程通过 `wait()` 回收

*进程管理的其他相关系统调用*
- 优先级控制
  - `nice()`指定进程的初始优先级
  - Unix系统中进程优先级会随执行时间而衰减
- 进程调试
  - `ptrace()`允许一个进程控制另一个进程的执行
  - 设置断点和查看寄存器等
- 定时
  - `sleep()`可以让进程在定时器的等待队列中等待指定时间

*进程管理与进程状态的关系*
- 进程管理相关的系统调用可能会影响进程的状态
  #figure(
    image("pic/2025-10-29-02-05-09.png", width: 80%),
    numbering: none,
  )

=== 关于`Fork()`的思考

==== `Fork()`的开销

传统实现中，fork() 需要：
- 为子进程分配新的地址空间
- 复制父进程的整个内存（包括堆、栈、数据段）
- 复制文件描述符表
- 复制 CPU 上下文（寄存器状态等）
- 建立新的页表结构
在99%的情况里，我们在调用`fork()`之后调用`exec()`
- 在`fork()`操作中内存复制是没有作用的，写时复制
- 子进程将可能关闭打开的文件和网络连接

`vfork()`创建进程时，不再创建一个同样的内存映像
- 轻量级`fork()`
- 子进程应该几乎立即调用`exec()`
- 现在使用 表复制与写时复制（COW, Copy-On-Write）

  #figure(
    image("pic/2025-10-29-02-05-55.png", width: 80%),
    numbering: none,
  )
  - 左图（Before modification）：
    - 父子进程页表均指向相同的物理页（Frame 1998）
  - 右图（After modification）：
    - 当任一进程尝试写入该页时，操作系统会复制该页
    - 子进程的页表更新为指向新的 Frame（Frame 2038）
    - 父进程仍保留原 Frame（Frame 1998）
  - 机制：
    - 页被标记为“只读”
    - 当某一方写入时触发“页错误”
    - 内核复制该页内容
    - 更新页表，解除只读限制
  - 好处：
    - 延迟复制，避免无用的内存复制
    - 显著降低 `fork()` 的性能开销
    - 特别适合 `fork` 后立即调用 `exec()` 的场景

==== 重新思考`fork`

- 简单：没有参数
- 优雅：和`exec`分离
- 父子进程并发执行
- Fork is no longer simple
  - Fork encourages memory overcommit过度分配
  - Fork is incompatible with a single address space不兼容单一地址空间模型
  - Fork is incompatible with heterogeneous hardware-硬件环境错误
  - Fork infects an entire system-感染整个系统

性能分析：Fork is slow
#three-line-table[
  | 方法                           | 说明         | 时间增长趋势         |
  | ---------------------------- | ---------- | -------------- |
  | *fork + exec (fragmented)* | 父进程内存高度碎片化 | 随进程大小急剧线性上升    |
  | *fork + exec (dirty)*      | 父进程内存较“干净” | 增长较缓慢但仍明显      |
  | *posix_spawn*              | 一步创建+执行新程序 | 时间几乎恒定（≈0.5ms） |
]
*现代优化方案*
- `vfork()`
  - `vfork()` 是“轻量级 fork”，它不再复制父进程内存映像。
  - 机制：
    - 子进程与父进程共享同一地址空间
    - 父进程被暂停，直到子进程调用 `exec()` 或 `_exit()`
    - 禁止子进程修改内存（否则会破坏父进程）
  - 优点：
    - 不再分配内存
    - 不再复制页表
    - 几乎零开销
  - 缺点：
    - 子进程若访问或修改内存，后果严重
    - 只能用于“马上 `exec`” 的场景
- Copy-On-Write (COW)
  - 现代 `Linux fork()` 实际上已经完全采用 COW：
    - 父子共享页，只读保护
    - 仅在写入时才复制
    - 让 `fork()` 成为“几乎 O(1)”的操作
    - 但仍有页表复制开销
- `posix_spawn()`
  - `posix_spawn()`是现代系统中推荐的替代方案。
  - 它结合了 `fork()` 和 `exec()` 的优点，但不需要复制父进程页表。
  ```rust
  posix_spawn(&pid, "/bin/ls", NULL, NULL, argv, envp);
  ```
  - 直接创建并加载新进程
  - 减少内核空间与用户空间切换
  - 性能稳定
  - 安全性更高
  - 更适合多线程应用

#note(subname: [小结])[
  - 进程管理的系统调用接口
    - 功能：创建、退出、等待
    - 开发效率
      - `fork()`实现简单、
      - `spawn()`逻辑清晰
    - 执行效率
      - `fork()`在早期很高效，现在不适合多线程场景
      - `spawn()`目前看起来逻辑仍然清晰
]

== 单处理器调度

#note(subname: [问题])[
  - *调度问题的提出*
    - 现代计算机系统中，进程数常常多于 CPU 数。因此，操作系统必须通过 调度（Scheduling）算法 决定：
      - 哪个进程获得 CPU（Who gets the CPU next?）
      - 何时切换到下一个进程（When to switch?）
      - 如何保持系统的整体性能最优（How to optimize performance?）
    - 这就是 单处理器调度问题（Uniprocessor Scheduling Problem）。
  - *调度的目标（Scheduling Objectives）*
    - 操作系统调度的核心在于权衡——既要让系统高效，也要让用户满意。
    - 系统级目标（System-Oriented Goals）
      #three-line-table[
        | 目标                            | 含义               |
        | ----------------------------- | ---------------- |
        | *提高CPU利用率（CPU Utilization）* | 尽量避免CPU空闲。       |
        | *提高系统吞吐量（Throughput）*       | 单位时间内完成的进程数越多越好。 |
        | *降低系统开销*                    | 减少调度、切换和等待开销。    |
      ]
    - 用户级目标（User-Oriented Goals）
      #three-line-table[
        | 目标                         | 含义                     |
        | -------------------------- | ---------------------- |
        | *响应时间短（Response Time）*   | 用户交互系统中尤为重要。           |
        | *周转时间短（Turnaround Time）* | 批处理任务从提交到完成的总时间。       |
        | *等待时间短（Waiting Time）*    | 进程在就绪队列中等待 CPU 的时间。    |
        | *公平性（Fairness）*          | 每个进程都有机会获得 CPU，不被长期饿死。 |
      ]
  - *调度的分类（Classification）*
    - 按发生时机（When to schedule）
      #three-line-table[
        | 类型                         | 时机                       | 特点          |
        | -------------------------- | ------------------------ | ----------- |
        | *非抢占式调度（Non-preemptive）* | 进程主动放弃 CPU（如 I/O、退出）     | 简单，切换少，但响应慢 |
        | *抢占式调度（Preemptive）*      | 系统强制切换（如时间片用完、优先级更高任务到来） | 响应快，但开销大    |
      ]
    - 按系统对象（What to schedule）
      #three-line-table[
        | 层级                               | 描述                         |
        | -------------------------------- | -------------------------- |
        | *长期调度（Long-term scheduling）*   | 控制进入系统的作业数（决定“是否执行”）       |
        | *中期调度（Medium-term scheduling）* | 控制进程在内存与外存之间的交换（决定“是否暂停”）  |
        | *短期调度（Short-term scheduling）*  | 在就绪队列中选择下一个要执行的进程（决定“谁执行”） |
      ]
  - *调度的基本机制：排队模型（Queuing Model）*
    #three-line-table[
      | 队列                    | 含义          |
      | --------------------- | ----------- |
      | *就绪队列（Ready Queue）* | 等待CPU的进程    |
      | *等待队列（Wait Queue）*  | 等待I/O或事件的进程 |
      | *执行队列（Running）*     | 当前占用CPU的进程  |
    ]
  - *进程切换时机（Context Switch Triggers）*
    #three-line-table[
      | 触发时机                   | 说明                             |
      | ---------------------- | ------------------------------ |
      | ① 当前进程*主动放弃CPU*      | 调用 `wait()`、`sleep()`、I/O 请求等。 |
      | ② 当前进程*终止*           | 执行完毕或异常退出。                     |
      | ③ 有*更高优先级的进程到达*      | 抢占式调度触发。                       |
      | ④ *时间片用完*            | 时间片轮转算法中的强制切换。                 |
      | ⑤ 系统调用或中断返回时*检测调度标志* | 比如从系统调用返回时发现有就绪进程。             |
    ]
  - 调度算法的设计要素（How to schedule）
    - Selection Function（选择函数）
    - Decision Mode（决策模式）
    - Queue Discipline（排队纪律）
  - 调度算法的常见指标（Evaluation Metrics）
    #three-line-table[
      | 指标                        | 定义                | 越小越好 / 越大越好 |
      | ------------------------- | ----------------- | ----------- |
      | *CPU利用率*                | CPU 实际工作时间 / 总时间  | 越大越好        |
      | *吞吐量（Throughput）*       | 单位时间内完成的进程数       | 越大越好        |
      | *周转时间（Turnaround Time）* | 从提交到完成的总时间        | 越小越好        |
      | *等待时间（Waiting Time）*    | 就绪队列中等待的时间        | 越小越好        |
      | *响应时间（Response Time）*   | 第一次响应用户的时间        | 越小越好        |
      | *公平性（Fairness）*         | 各进程获得 CPU 的比例是否合理 | 越平衡越好       |
    ]
]

=== 处理机调度概念

==== 处理机调度的时机和策略

*CPU资源的时分复用*
- 进程切换：CPU资源的当前占用者切换
  - 保存当前进程在PCB中的执行上下文(CPU状态)
  - 恢复下一个进程的执行上下文
- 处理机调度 Processor Scheduling
  - 从就绪队列中挑选下一个占用CPU运行的进程
  - 从多个可用CPU中挑选就绪进程可使用的CPU资源
- 调度器：挑选就绪进程的内核函数
- 调度策略
*调度时机*
- 内核执行调度的条件
  - 进程从运行状态切换到等待/就绪状态
  - 进程被终结了
- 非抢占系统
  - 当前进程主动放弃CPU时
- 可抢占系统
  - 中断请求被服务例程响应完成时
*调度策略*
- 确定如何从就绪队列中选择下一个执行进程
- 要解决的问题
  - 通过什么样的准则来选择？
  - 挑选就绪队列中的哪一个进程？
- 调度算法
  - 在内核调度中实现的调度策略
- 比较调度算法的准则
  - 哪一个策略/算法较好?

*处理机资源的使用模式*
- 进程在CPU计算和I/O操作间交替
  - 每次调度决定在下一个CPU计算时将哪个工作交给CPU
  - 在时间片机制下，进程可能在结束当前CPU计算前被迫放弃CPU
  #figure(
    image("pic/2025-10-29-02-30-00.png", width: 80%),
    numbering: none,
  )
  #three-line-table[
    | 类型                    | 特征                 | 调度策略偏好          |
    | --------------------- | ------------------ | --------------- |
    | *I/O密集型（I/O-bound）* | 频繁进行I/O操作，CPU计算时间短 | 适合短响应时间策略（如RR）  |
    | *CPU密集型（CPU-bound）* | 主要进行大量计算，I/O等待少    | 适合长时间运行策略（如SJF） |
  ]

==== 比较调度算法的准则

*比较调度算法的准则*
#three-line-table[
  | 指标                        | 定义             | 目标    | 说明                 |
  | ------------------------- | -------------- | ----- | ------------------ |
  | *CPU使用率*                | CPU 忙碌时间 / 总时间 | 越高越好  | 衡量系统资源利用率          |
  | *吞吐量（Throughput）*       | 单位时间完成的进程数     | 越多越好  | 体现系统总体处理能力         |
  | *周转时间（Turnaround Time）* | 从作业提交到完成的总时间   | 越短越好  | 包括等待 + 执行 + I/O 时间 |
  | *就绪等待时间（Waiting Time）*  | 进程在就绪队列中等待的总时间 | 越短越好  | 衡量调度公平性和响应效率       |
  | *响应时间（Response Time）*   | 从请求提交到首次响应的时间  | 越短越好  | 对交互式系统至关重要         |
  | *公平性（Fairness）*         | 各进程获得CPU机会是否均等 | 越均衡越好 | 防止进程“饿死”           |
]

*吞吐量与延迟的对立关系（Bandwidth vs. Latency）*
- 延迟（Latency）与吞吐量（Throughput）之间的平衡关系：
  - 若系统过于频繁地切换（保证低延迟），则上下文切换开销大 → 吞吐量下降
  - 若系统长时间运行同一任务（保证高吞吐量），则其他任务响应慢 → 延迟上升

*响应时间准则（Response Time）*
- 响应时间是用户最直观感受的指标，尤其在交互式系统中
- 减少响应时间
  - 及时处理用户的输入请求，尽快将输出反馈给用户
- 减少平均响应时间的波动
  - 在交互系统中，可预测性比高差异低平均更重要
- 低延迟调度改善了用户的交互体验
  - 如果移动鼠标时，屏幕中的光标没动，用户可能会重启电脑
- 响应时间是操作系统的计算延迟

*吞吐量准则（Throughput）*
- 提高吞吐量的主要手段
  #three-line-table[
    | 方法           | 作用                        |
    | ------------ | ------------------------- |
    | *减少系统开销*   | 降低调度和上下文切换频率              |
    | *提高CPU利用率* | 避免CPU空闲（让I/O进程和CPU进程交错运行） |
    | *减少等待时间*   | 让就绪进程尽快获得CPU执行            |
  ]
- 让 CPU、I/O、内存 “三者并行工作”，而不是互相等待
- 吞吐量是操作系统的计算带宽

*公平性准则（Fairness）*
- 公平的定义
  - 保证每个进程占用相同的CPU时间
  - 保证每个进程的就绪等待时间相同
- 公平通常会增加平均响应时间

=== 调度算法

==== FCFS、SJF、SRT和HRRN

===== 先来先服务算法FCFS

*先来先服务调度算法FCFS* FCFS: First Come, First Served
- 依据进程进入就绪状态的先后顺序排列
- 非抢占式：运行中的进程不会被中途打断
- 进程进入等待或结束状态时，就绪队列中的下一个进程占用CPU
- 指标
  - FCFS算法的周转时间

*先来先服务调度算法示例*
- 假设有三个进程：
  #three-line-table[
    | 进程 | 执行时间 |
    | -- | ---- |
    | P₁ | 12   |
    | P₂ | 3    |
    | P₃ | 3    |
  ]
- 调度顺序一：P₁ → P₂ → P₃
  - Gantt 图（时间轴）：
    ```
    |----P1----|--P2--|--P3--|
    0          12    15    18
    ```
    平均周转时间：
    $
      T = ((12-0) + (15-0) + (18-0)) / 3 = 15
    $
- 调度顺序二：P₂ → P₃ → P₁
  - Gantt 图（时间轴）：
    ```
    |--P2--|--P3--|----P1----|
    0      3      6      18
    ```
    平均周转时间：
    $
      T = ((3-0) + (6-0) + (18-0)) / 3 = 9
    $
  换序后平均周转时间显著降低！

*特点总结*
- 优点：简单
- 缺点
  - 平均等待时间波动较大
  - 短作业/任务/进程可能排在长进程后面
  - I/O资源和CPU资源的利用率较低
    - CPU密集型进程会导致I/O设备闲置时
    - I/O密集型进程也等待

===== 短作业优先算法SJF

*短作业优先调度算法SJF* SJF: Shortest Job First
- 选择就绪队列中执行时间最短作业/进程占用CPU进入运行状态
- 非抢占式：运行的进程不会被中断
- 就绪队列按预期的执行时间来排序
- 目标：最小化平均周转时间
  #figure(
    image("pic/2025-10-29-02-41-10.png", width: 80%),
    numbering: none,
  )

*短作业优先调度算法的特征*
- 具有最优平均周转时间
- 修改作业/进程执行顺序不会增加平均周转时间

*短作业优先调度算法的特征*
- 可能导致饥饿
  - 连续的短作业/进程流会使长作业/进程无法获得CPU资源
- 需要预知未来
  - 如何预估下一个CPU计算的持续时间
  - 简单的解决办法：询问用户
    - 用户欺骗就杀死相应进程
    - 用户不知道怎么办？

*短作业优先算法的执行时间预估*
- 用历史的执行时间来预估未来的执行时间 指数平滑法
  $
    tau_(n+1) = alpha t_n + (1 - alpha) tau_n
  $
  - 其中：
    - $tau_(n+1)$ 是对第$n+1$次CPU计算时间的预估
    - $t_n$ 是第$n$次CPU计算的实际时间
- 执行时间预估
  #figure(
    image("pic/2025-10-29-02-43-48.png", width: 80%),
    numbering: none,
  )

===== 短剩余时间优先算法SRT

*短剩余时间优先调度算法SRT* SRT: Shortest Remaining Time
- *抢占*调度机制
- 有新的进程就绪，且新进程的*服务时间小于当前进程的剩余时间*，则转到新的进程执行

适用场景：
- 对实时响应要求高
- 进程到达时间不确定
- 系统必须快速响应新任务

===== 高响应比优先算法HRRN

*高响应比优先调度算法HRRN* HRRN: Highest Response Ratio Next
- 非抢占式调度算法
- *高响应比优先调度算法主要用于作业调度*
- 该算法是对FCFS调度算法和SJF调度算法的一种综合平衡，同时考虑*每个作业的就绪等待时间和估计的运行时间*
- 在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出*响应比最高*的作业投入运行
- 选择就绪队列中*响应比$R$值*最高的进程

  $
    R = (W + S) / S = 1 + (W / S)
  $
  - 其中：
    - $R$ 是响应比
    - $W$ 是进程的*就绪等待时间*
    - $S$ 是进程的预估服务时间（*执行时间*）
- 特点
  - 在短作业优先算法的基础上改进
  - 关注进程的等待时间
  - 防止无限期推迟

#three-line-table[
  | 算法       | 类型  | 抢占性 | 优点         | 缺点     | 典型应用     |
  | -------- | --- | --- | ---------- | ------ | -------- |
  | *FCFS* | 非抢占 | 否   | 简单、公平      | 短任务等待长 | 批处理系统    |
  | *SJF*  | 非抢占 | 否   | 平均周转时间最优   | 长任务饥饿  | 批处理、任务预测 |
  | *SRT*  | 抢占  | 是   | 响应快、最优等待时间 | 开销大    | 实时系统     |
  | *HRRN* | 非抢占 | 否   | 综合平衡、公平性高  | 仍需估算时间 | 作业调度系统   |
]

==== 时间片轮转算法RR

*时间片轮转调度算法RR* RR: Round Robin
- 时间片
  - 分配处理机资源的基本时间单元
  - CPU执行的最大小时间单位
- 算法思路
  - 时间片结束时，按FCFS算法切换到下一个就绪进程
  - 每隔(n – 1)个时间片进程执行一个时间片q
  #figure(
    image("pic/2025-10-29-02-49-45.png", width: 80%),
    numbering: none,
  )
  - 若进程在时间片内完成：
    - CPU立即切换至下一个
  - 若时间片用完：
    - 系统触发中断，强制调度
    - 当前进程重新排到队尾等待下一轮

*时间片轮转算法示例*
- 假设有 4 个进程：
  #three-line-table[
    | 进程 | 执行时间 |
    | -- | ---- |
    | P₁ | 53   |
    | P₂ | 8    |
    | P₃ | 68   |
    | P₄ | 24   |
  ]
  设时间片`q = 20`，忽略上下文切换开销。
- 执行顺序（Gantt图）
  ```
  | P1 | P2 | P3 | P4 | P1 | P3 | P4 | P1 | P3 |
  0    20   28   48   68   88  108 112 125 145 153
  ```
- 等待时间计算
  #three-line-table[
    | 进程 | 等待时间计算                      | 等待时间 |
    | -- | --------------------------- | ---- |
    | P₁ | (68−20)+(112−88)=72         | 72   |
    | P₂ | (20−0)=20                   | 20   |
    | P₃ | (28−0)+(88−48)+(125−108)=85 | 85   |
    | P₄ | (48−0)+(108−68)=88          | 88   |
  ]
  - 平均等待时间：
    $
      T = (72 + 20 + 85 + 88) / 4 = 66.25
    $

*时间片轮转算法的时间片长度参数*
- RR算法开销： 额外的上下文切换
- 时间片太大
  - 等待时间过长，极限情况退化成FCFS
- 时间片太小
  - 反应迅速，但产生大量上下文切换
  - 大量上下文切换开销影响到系统吞吐量
- 时间片长度选择目标
  - 选择一个合适的时间片长度
  - 经验规则：维持上下文切换开销处于1%以内

*比较FCFS和RR*
- #three-line-table[
    | 比较维度     | FCFS          | RR          |
    | -------- | ------------- | ----------- |
    | *调度类型* | 非抢占式          | 抢占式         |
    | *公平性*  | 按到达顺序         | 所有进程公平轮转    |
    | *响应时间* | 不可预测（取决于前序进程） | 响应稳定且短      |
    | *吞吐量*  | 高（切换少）        | 稍低（切换多）     |
    | *适用场景* | 批处理           | 交互式系统、多用户环境 |
  ]
- #three-line-table[
    |       时间片      | P₁ | P₂  | P₃ | P₄  | 平均等待时间    |
    | :------------: | -- | --- | -- | --- | --------- |
    |     RR(q=1)    | 84 | 22  | 85 | 57  | 62        |
    |     RR(q=5)    | 82 | 20  | 85 | 58  | 61.25     |
    |     RR(q=8)    | 80 | 8   | 85 | 56  | 57.25     |
    |    RR(q=10)    | 82 | 10  | 85 | 68  | 61.25     |
    |    RR(q=20)    | 72 | 20  | 85 | 88  | 66.25     |
    |  *Best FCFS* | 32 | 0   | 85 | 8   | *31.25* |
    | *Worst FCFS* | 68 | 145 | 0  | 121 | *83.5*  |
  ]

==== MQ、MLFQ和FSS

===== 多级队列调度算法 MQ

*多级队列调度算法 MQ* MQ: Multi-level Queue
- 就绪队列被划分成*多个独立的子队列*
  - 如：前台进程(交互)子队列、后台进程(批处理)子队列
  - 同一优先级的进程属于某个队列，且不能跨越队列
  - 每个队列拥有自己的调度策略
    - 如：前台进程–RR、后台进程–时间片大的RR/FCFS
- *调度规则*
  - 规则1：如果A的优先级 > B的优先级，运行A（不运行B）
  - 规则2：如果A的优先级 = B的优先级，轮转运行A和B
- *队列间的调度*
  - 固定优先级
    - 先处理前台(交互)进程，然后处理后台进程
    - 可能导致饥饿
  - 时间片轮转
    - 每个队列都得到一个确定的能够调度其进程的CPU总时间
    - 如：80%CPU时间用于前台进程，20%CPU时间用于后台进程

===== 多级反馈队列调度算法 MLFQ

*多级反馈队列调度算法 MLFQ* MLFQ: Multi-level Feedback Queue
- 1962年，MIT教授Corbato首次提出多级反馈队列，应用于兼容时分共享系统（CTSS-Compatible Time-Sharing System）
- 解决两方面的问题
  - 如何在不知道工作要运行多久的情况下，优化*周转时间*
  - 如何降低*响应时间*，给交互用户很好的交互体验
- 关键问题：没有完备的知识如何调度？
  - 对进程工作长度未知情况下，如何构建能同时减少响应时间和周转时间的调度程序？
- 启发：从历史中学习
  - 用历史经验预测未来
- 继承Multi Queue的调度规则
  - 如果A的优先级 > B的优先级，运行A（不运行B）
  - 如果A的优先级 = B的优先级，轮转/FIFO运行A和B
- *基本调度规则*
  - 工作进入系统时，放在最高优先级（最上层队列）
  - 如果进程在当前的时间片没有完成，则降到下一个优先级
  - 如果工作在其时间片以内主动释放CPU，则优先级不变
  - 时间片大小随优先级级别增加而增加
  #figure(
    image("pic/2025-10-29-03-00-15.png", width: 80%),
    numbering: none,
  )

*三个优先级队列的MLFQ调度例子*
- CPU密集型进程首先进入最高优先级队列
- 执行1ms时间片后，调度器将进程的优先级减1，进入次高优先级队列
- 执行2ms时间片后，进入系统的最低优先级队列，一直留在那里，按4ms时间片执行

*多级反馈队列调度算法MLFQ*
- MLFQ算法的特征
  - CPU密集型进程的优先级下降很快
  - I/O密集型进程停留在高优先级
- 潜在问题
  - CPU密集型进程会饥饿
  - 恶意进程会想办法留在高优先级
*基本调度规则*
- 如果A的优先级 > B的优先级，运行A（不运行B）
- 如果A的优先级 = B的优先级，轮转/FIFO运行A和B
- 工作进入系统时，放在最高优先级（最上层队列）
- 一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）
- 经过一段时间S，就将系统中所有工作重新加入最高优先级队列

===== 公平共享调度算法 FSS

*公平共享调度算法 FSS* FSS: Fair Share Scheduling
- 控制用户对系统资源的访问
  - 不同用户拥有多个进程
  - 按用户优先级分配资源
  - 保证不重要的用户无法垄断资源
  - 未使用的资源按比例分配

#three-line-table[
  | 算法       | 类型  | 抢占性 | 优点       | 缺点       | 应用场景   |
  | -------- | --- | --- | -------- | -------- | ------ |
  | *FCFS* | 非抢占 | 否   | 简单       | 短任务等待长任务 | 批处理    |
  | *SJF*  | 非抢占 | 否   | 最小平均周转时间 | 需预测执行时间  | 批处理    |
  | *SRT*  | 抢占  | 是   | 响应快      | 饥饿风险     | 实时系统   |
  | *HRRN* | 非抢占 | 否   | 公平兼顾效率   | 实现复杂     | 作业调度   |
  | *RR*   | 抢占  | 是   | 公平、响应好   | 吞吐降低     | 交互系统   |
  | *MLFQ* | 抢占  | 是   | 响应快、动态调节 | 饥饿风险、复杂  | 通用操作系统 |
  | *FSS*  | 抢占  | 是   | 用户级公平    | 实现复杂     | 多用户系统  |
]

#note(subname: [小结])[
  - 处理机调度目标
    - 效率：CPU利用率、吞吐量
    - 延时：响应时间、周转时间、等待时间
    - 公平性
  - 调度算法
    - 就绪队列顺序：FCFS、SJF、SRT、HRRN
    - 进程切换时机：RR
    - 公平：MQ、MLFQ、FSS
]

== 实时调度

#note(subname: [问题])[
  - 调度算法有可能保存任务一定在截止时间前完成吗？
    - 如果不能在截止时间前完成，将导致严重后果
    - 实时调度的核心问题是：能否在任务的“截止时间”前完成它？
  - 实时系统的基本定义
    #three-line-table[
      | 类型                        | 定义               | 后果                 |
      | ------------------------- | ---------------- | ------------------ |
      | *硬实时系统（Hard Real-Time）* | 所有关键任务必须在截止时间前完成 | 超时即系统失败（如飞控、核反应控制） |
      | *软实时系统（Soft Real-Time）* | 超过截止时间只会导致性能下降   | 超时可容忍（如视频播放、游戏）    |
    ]
  - 实时任务的特征参数
    - 每个实时任务$T_i$一般用四元组表示：
      $
        T_i = (C_i, P_i, D_i, R_i)
      $
      #three-line-table[
        | 符号      | 含义                              |
        | ------- | ------------------------------- |
        | $C_i$ | 任务执行所需 CPU 时间（Computation Time） |
        | $P_i$ | 周期（Period）或到达间隔                 |
        | $D_i$ | 截止时间（Deadline）                  |
        | $R_i$ | 实际完成时间（Response Time）           |
      ]
  - 实时调度的目标
    - 调度算法设计目标：
      - 保证每个任务在截止时间内完成（Deadline Meet）
      - 优化 CPU 利用率
      - 响应及时、抖动小
      - 对突发任务具备可预测性
  - 实时调度的类型
    #three-line-table[
      | 类别                | 说明             | 示例                             |
      | ----------------- | -------------- | ------------------------------ |
      | *静态调度（Static）*  | 调度在运行前确定（离线计算） | RMS（Rate Monotonic Scheduling） |
      | *动态调度（Dynamic）* | 调度在运行时动态决定     | EDF（Earliest Deadline First）   |
    ]
]

=== 实时操作系统

*实时操作系统的定义*
- 实时操作系统的定义
  - 正确性依赖于其*时间和功能*两方面的操作系统
- 实时操作系统的性能指标
  - 时间约束的*及时性*（deadlines）
  - 速度和平均性能相对不重要
- 实时操作系统的特性
  - 时间约束的*可预测性*

*实时操作系统的分类*
#three-line-table[
  | 类型                      | 特征                   | 示例        |
  | ----------------------- | -------------------- | --------- |
  | *硬实时（Hard Real-Time）* | 必须在截止时间前完成；超时 = 系统失败 | 飞机控制、医疗设备 |
  | *软实时（Soft Real-Time）* | 重要进程有高优先级，尽量按时完成；偶尔延迟可接受       | 视频播放、在线游戏 |
]

#newpara()

*实时任务（Real-Time Task）*
- 任务（工作单元）
  - 一次计算，一次文件读取，一次信息传递等等
- 任务属性
  - 完成任务所需要的资源
  - 定时参数
  #figure(
    image("pic/2025-10-29-13-22-50.png", width: 80%),
    numbering: none,
  )
- 任务属性
  #three-line-table[
    | 参数     | 含义            |
    | ------ | ------------- |
    | 执行时间 e | 任务的最大执行时间     |
    | 周期 p   | 相邻两次任务请求的间隔时间 |
    | 截止时间 D | 必须在此时间前完成     |
    | 请求时刻   | 任务被激活（到达）的时间点 |
  ]
- *周期实时任务（Periodic Real-Time Tasks）*
  - 周期实时任务：一系列相似的任务
    - 任务有规律地重复
    - 周期$p =$任务请求时间间隔 ($0 < p$)
    - 执行时间$e =$最大执行时间 ($0 < e < p$)
    - 使用率$U = e/p$
    #figure(
      image("pic/2025-10-29-13-32-51.png", width: 80%),
      numbering: none,
    )
  - *可调度（schedulable）*
    $
      U = sum_i e_i/p_i
    $
    - $U<=1$：可调度
    - $U>1$：不可调度

*软时限与硬时限（Soft vs Hard Deadline）*
- 硬时限（Hard deadline）
  - 错过任务时限会导致灾难性或非常严重的后果
  - 必须验证，在*最坏情况下能够满足*时限
- 软时限(Soft deadline)
  - 通常能满足任务时限
  - 如有时不能满足，则降低要求
  - *尽力保证满足*任务时限

*实时任务可调度性（Schedulability）*
- 可调度性（Schedulability）表示系统能否在所有情况下，保证每个任务都在其截止时间前完成
- 可调度表示一个实时操作系统能够满足任务时限要求
  - 需要确定实时任务的执行顺序
  - *静态*优先级调度：任务执行过程中*不会*改变任务的优先级
  - *动态*优先级调度：任务执行过程中*会*改变任务的优先级
  #figure(
    image("pic/2025-10-29-13-33-02.png", width: 80%),
    numbering: none,
  )

=== 实时调度

*实时调度*：在保证所有任务在截止时间前完成的前提下，实现CPU的最优利用
- *静态*优先级调度：速率单调调度算法(RM, Rate Monotonic)
  - 通过周期安排优先级
  - *周期越短优先级越高*
  - 执行周期最短的任务
- *动态*优先级调度：最早截止时间优先算法 (EDF, Earliest Deadline First)
  - 截止时间越早优先级越高
  - 执行*离截止时间最近的任务*
- 如果任务间有*共享资源占用*的情况，高优先级任务可能会被延误执行！

==== 速率单调调度算法(RM, Rate Monotonic)

*速率单调调度算法(RM)*
- 是一种静态优先级调度算法
- 根据任务周期来确定任务优先级（周期越短优先级越高，抢占式）
- 周期越短，优先级越高（即执行频率高的任务更重要）

*示例*
- 示例 1
  - 进程P1：e=20 p=50
  - 进程P2：e=35 p=100
  #figure(
    image("pic/2025-10-29-13-41-29.png", width: 80%),
    numbering: none,
  )
  - RM 能保证截止时间满足的条件
    $
      U = sum_i (e_i/p_i) <= n(2^(1/n) - 1)
    $
- 示例 2
  - 进程P1：e=30 p=60
  - 进程P2：e=35 p=80
  #figure(
    image("pic/2025-10-29-13-42-59.png", width: 80%),
    numbering: none,
  )
  - RM 能保证截止时间满足的条件
    $
      n = 2 => U <= 2(2^(1/2) - 1) = 0.828\
      U = 25/50 + 35/80 = 0.9375 > 0.828
    $
    不可调度！

==== 最早截止时间优先（EDF, Earliest Deadline First）

*最早截止时间优先调度算法(EDF)*
- 固定优先级的问题：有的任务可能错过期限
- 截止时间越早的任务优先执行
- 属于动态优先级调度算法，优先级随时间变化

调度策略：
- 每当有新任务到达，系统检查所有任务的截止时间
- 优先执行截止时间最早的任务
- 允许抢占

*示例*
- 进程P1：e=10 p=20
- 进程P2：e=25 p=50
  #figure(
    image("pic/2025-10-29-13-45-54.png", width: 80%),
    numbering: none,
  )
  #figure(
    image("pic/2025-10-29-13-46-18.png", width: 80%),
    numbering: none,
  )
  #figure(
    image("pic/2025-10-29-13-46-38.png", width: 80%),
    numbering: none,
  )
- 任务的优先级根据任务的*截止时间动态分配*。截止时间越短，优先级越高。
  #figure(
    image("pic/2025-10-29-13-47-35.png", width: 80%),
    numbering: none,
  )
- 可调度条件：
  $
    U = sum_i (e_i/p_i) <= 1
  $

==== 最低松弛度优先（LLF, Least Laxity First）

*最低松弛度优先调度算法(LLF)*
- 动态优先级调度算法
- 优先执行“最紧迫”的任务
- 根据任务紧急或者松弛程度，来确定任务优先级
  - 任务紧急度越高，优先级越高
  - *松弛度=必须完成时间-本身还需要运行时间-当前时间*=距离截止时间还剩多少时间 - 任务还需要的执行时间

*示例*
- 进程P1：e=10 p=20
- 进程P2：e=25 p=50
  #figure(
    image("pic/2025-10-29-13-53-05.png", width: 80%),
    numbering: none,
  )

#three-line-table[
  | 调度算法    | 优先级类型 | 依据          | 可调度条件                | 优点       | 缺点      |
  | ------- | ----- | ----------- | -------------------- | -------- | ------- |
  | *RM*  | 静态    | 周期越短优先级越高   | $U <= n(2^(1/n)-1)$ | 实现简单     | 不完全最优   |
  | *EDF* | 动态    | 截止时间越早优先级越高 | $U <= 1$            | 最优（单CPU） | 实现复杂    |
  | *LLF* | 动态    | 松弛度越小优先级越高  | $U <= 1$            | 理论最优、响应快 | 开销大、不稳定 |
]
#three-line-table[
  | 特点    | RM     | EDF    | LLF     |
  | ----- | ------ | ------ | ------- |
  | 优先级类型 | 固定     | 动态     | 动态      |
  | 可调度性  | 部分可保证  | 理论最优   | 理论最优但复杂 |
  | 适用场景  | 周期任务稳定 | 一般实时系统 | 高精度实时控制 |
  | 抢占支持  | 支持     | 支持     | 支持      |
  | 实现复杂度 | 低      | 中      | 高       |
]

=== 优先级反置

*优先级反置（Priority Inversion）*
- 高优先级进程长时间等待低优先级进程所占用资源的现象
- *基于优先级的可抢占调度算法存在优先级反置问题*
  - 优先级：T1>T2>T3
  #figure(
    image("pic/2025-10-29-13-58-13.png", width: 80%),
    numbering: none,
  )
  - 简单说：
    - 高优先级任务 T₁ 想获取某个资源 S
    - 但资源 S 已被低优先级任务 T₃ 占用
    - T₁ 必须等待 T₃ 释放资源
    - 此时若中间有中优先级任务 T₂ 抢占 CPU
    - T₂ 反而阻塞了高优先级的 T₁ ——这就是“优先级反置（Priority Inversion）”
  #figure(
    image("pic/2025-10-29-14-00-32.png", width: 80%),
    numbering: none,
  )
- 优先级反置的危害
  #three-line-table[
    | 问题      | 说明                             |
    | ------- | ------------------------------ |
    | 实时性破坏 | 高优先级任务可能无法在截止时间前完成             |
    | 不可预测 | 阻塞时间难以分析，破坏系统的可调度性             |
    | 死锁风险  | 若多个资源交叉占用，可能形成死锁               |
    | 实例   | NASA 火星探路者任务中曾因此问题导致系统重启（1997） |
  ]

*优先级反置的解决机制*
- 优先级继承（Priority Inheritance Protocol, PIP）
- 优先级天花板协议（Priority Ceiling Protocol, PCP）

*优先级继承(Priority Inheritance)*
- 占用资源的低优先级进程继承*申请资源的高优先级进程的优先级*
- 只在想占有资源的高优先级进程被阻塞时，才提高占有资源的低优先级进程的优先级
  - 注：临界区：互斥访问共享资源的代码片段
  #figure(
    image("pic/2025-10-29-14-02-51.png", width: 80%),
    numbering: none,
  )
  - 低优先级 T₃ 占用资源 S
  - 高优先级 T₁ 请求资源 S，被阻塞
  - T₃ 临时继承 T₁ 的优先级（提升至50）
  - T₃ 以高优先级执行完临界区，释放资源
  - T₃ 优先级恢复为原值，T₁ 获得资源继续执行
- 优点：
  - 避免了高优先级任务长时间等待
  - 限制了反置的持续时间
- 缺点：
  - 若多个任务竞争多个资源，继承链复杂
  - 实现开销较高

*优先级天花板协议（Priority Ceiling Protocol, PCP）*
- 每个共享资源都设一个“优先级天花板”（Priority Ceiling）——即所有可能访问该资源的任务的最高优先级
- *占用资源进程的优先级与所有可能申请该资源进程的最高优先级相同*
  - 不管是否发生等待，都提升占用资源进程的优先级
  - 优先级高于系统中所有被锁定的资源的优先级上限，任务执行临界区时就不会被阻塞

#note(subname: [小结])[
  - 实时操作系统
    - 实时操作系统的定义、实时任务
  - 实时调度
    - 速率单调调度算法、最早截止时间优先算法、最低松弛度优先算法
  - 优先级反置
    - 优先级继承、优先级天花板协议
]
